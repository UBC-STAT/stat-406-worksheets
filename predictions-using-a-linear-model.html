<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>1 Predictions using a linear model | UBC Stat 406 Worksheets</title>
<meta name="author" content="Daniel J. McDonald and Matías Salibán-Barrera">
<meta name="description" content="In this document we will explore (rather superficially) some challenges found when trying to estimate the forecasting properties (e.g. the mean squared prediction error) of a (linear) predictor....">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="1 Predictions using a linear model | UBC Stat 406 Worksheets">
<meta property="og:type" content="book">
<meta property="og:url" content="https://ubc-stat.github.io/stat-406-worksheets/predictions-using-a-linear-model.html">
<meta property="og:description" content="In this document we will explore (rather superficially) some challenges found when trying to estimate the forecasting properties (e.g. the mean squared prediction error) of a (linear) predictor....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="1 Predictions using a linear model | UBC Stat 406 Worksheets">
<meta name="twitter:description" content="In this document we will explore (rather superficially) some challenges found when trying to estimate the forecasting properties (e.g. the mean squared prediction error) of a (linear) predictor....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">UBC Stat 406 Worksheets</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Stat 406 Worksheets</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Module 0 – Review</li>
<li><a class="active" href="predictions-using-a-linear-model.html"><span class="header-section-number">1</span> Predictions using a linear model</a></li>
<li class="book-part">Module 1 – Model Selection</li>
<li><a class="" href="predictions-using-a-linear-model-continued.html"><span class="header-section-number">2</span> Predictions using a linear model (continued)</a></li>
<li><a class="" href="cross-validation-concerns.html"><span class="header-section-number">3</span> Cross-validation concerns</a></li>
<li><a class="" href="comparing-models.html"><span class="header-section-number">4</span> Comparing models</a></li>
<li class="book-part">Module 2 – Regression</li>
<li><a class="" href="ridge-regression.html"><span class="header-section-number">5</span> Ridge regression</a></li>
<li><a class="" href="lasso.html"><span class="header-section-number">6</span> LASSO</a></li>
<li><a class="" href="non-parametric-regression.html"><span class="header-section-number">7</span> Non-parametric regression</a></li>
<li><a class="" href="kernel-regression-local-regression.html"><span class="header-section-number">8</span> Kernel regression / local regression</a></li>
<li><a class="" href="regression-trees.html"><span class="header-section-number">9</span> Regression trees</a></li>
<li><a class="" href="pruning-regression-trees-with-rpart.html"><span class="header-section-number">10</span> Pruning regression trees with rpart</a></li>
<li class="book-part">Module 3 – Classification</li>
<li><a class="" href="parametric-classifiers.html"><span class="header-section-number">11</span> Parametric classifiers</a></li>
<li><a class="" href="qda.html"><span class="header-section-number">12</span> QDA</a></li>
<li><a class="" href="classification-trees.html"><span class="header-section-number">13</span> Classification Trees</a></li>
<li class="book-part">Module 4 – Modern techniques</li>
<li><a class="" href="bagging-for-regression.html"><span class="header-section-number">14</span> Bagging for regression</a></li>
<li><a class="" href="bagging-for-classification.html"><span class="header-section-number">15</span> Bagging for classification</a></li>
<li><a class="" href="random-forests.html"><span class="header-section-number">16</span> Random Forests</a></li>
<li><a class="" href="boosting-a-statistical-learning-perspective.html"><span class="header-section-number">17</span> Boosting (a Statistical Learning perspective)</a></li>
<li><a class="" href="what-is-adaboost-doing-really.html"><span class="header-section-number">18</span> What is Adaboost doing, really?</a></li>
<li><a class="" href="single-layer-neural-network.html"><span class="header-section-number">19</span> Single layer neural network</a></li>
<li class="book-part">Module 5 – Unsupervised learning</li>
<li><a class="" href="introduction.html"><span class="header-section-number">20</span> Introduction</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">21</span> Clustering</a></li>
<li><a class="" href="model-based-clustering.html"><span class="header-section-number">22</span> Model based clustering</a></li>
<li><a class="" href="hierarchical-clustering.html"><span class="header-section-number">23</span> Hierarchical clustering</a></li>
<li><a class="" href="references.html">References</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="alt-pca.html"><span class="header-section-number">A</span> PCA and alternating regression</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/ubc-stat/stat-406-worksheets">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="predictions-using-a-linear-model" class="section level1">
<h1>
<span class="header-section-number">1</span> Predictions using a linear model<a class="anchor" aria-label="anchor" href="#predictions-using-a-linear-model"><i class="fas fa-link"></i></a>
</h1>
<p>In this document we will explore (rather superficially)
some challenges found when trying to estimate the forecasting
properties (e.g. the mean squared prediction error) of a (linear) predictor. We will
use the air-pollution data set, which I have split into a <em>training set</em> and a <em>test set</em>.
The test set will be ignored when <strong>training</strong> our model (in the case of a linear
model, “<strong>training</strong>” simply means “<strong>when estimating the vector of linear regression
parameters</strong>”).</p>
<p>If you are interested in how these sets (<em>training</em> and <em>test</em>) were constructed:
I ran the following script (you
do not need to do this, as I am providing both data sets to you,
but you can re-create them yourself if you want to):</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"data/rutgers-lib-30861_CSV-1.csv"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">ii</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, each <span class="op">=</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span>
<span class="co"># this is the training set `pollution-train.dat`</span>
<span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="fl">2</span>, <span class="op">]</span>
<span class="co"># this is the test set `pollution-test.dat`</span>
<span class="va">x.te</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span>
<span class="co"># then I saved them to disk:</span>
<span class="co"># write.csv(x.tr, file='pollution-train.dat', row.names=FALSE, quote=FALSE)</span>
<span class="co"># write.csv(x.te, file='pollution-test.dat', row.names=FALSE, quote=FALSE)</span></code></pre></div>
<p>We now read the <strong>training</strong> data set from the file <code>pollution-train.dat</code>,
which is available <a href="pollution-train.dat">here</a>, and check that it was read properly:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/pollution-train.dat"</span>, header <span class="op">=</span> <span class="cn">TRUE</span>, sep <span class="op">=</span> <span class="st">","</span><span class="op">)</span>
<span class="co"># sanity check</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">x.tr</span><span class="op">)</span>
<span class="co">#&gt;   PREC JANT JULT OVR65 POPN EDUC HOUS DENS NONW WWDRK POOR HC NOX SO. HUMID</span>
<span class="co">#&gt; 1   36   27   71   8.1 3.34 11.4 81.5 3243  8.8  42.6 11.7 21  15  59    59</span>
<span class="co">#&gt; 2   35   23   72  11.1 3.14 11.0 78.8 4281  3.5  50.7 14.4  8  10  39    57</span>
<span class="co">#&gt; 3   44   29   74  10.4 3.21  9.8 81.6 4260  0.8  39.4 12.4  6   6  33    54</span>
<span class="co">#&gt; 4   47   45   79   6.5 3.41 11.1 77.5 3125 27.1  50.2 20.6 18   8  24    56</span>
<span class="co">#&gt; 5   43   35   77   7.6 3.44  9.6 84.6 6441 24.4  43.7 14.3 43  38 206    55</span>
<span class="co">#&gt; 6   53   45   80   7.7 3.45 10.2 66.8 3325 38.5  43.1 25.5 30  32  72    54</span>
<span class="co">#&gt;       MORT</span>
<span class="co">#&gt; 1  921.870</span>
<span class="co">#&gt; 2  997.875</span>
<span class="co">#&gt; 3  962.354</span>
<span class="co">#&gt; 4  982.291</span>
<span class="co">#&gt; 5 1071.289</span>
<span class="co">#&gt; 6 1030.380</span></code></pre></div>
<p>The response variable is <code>MORT</code>.
Our first step is to fit a
linear regression model with all available
predictors and look at a few diagnostic plots
where everything looks fine:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">MORT</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">full</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="02-lm-diagnostics-review_files/figure-html/full-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">full</span>, which <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="02-lm-diagnostics-review_files/figure-html/full-2.png" width="90%" style="display: block; margin: auto;"></div>
<p>We also take a look at the estimated coeficients:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">full</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = MORT ~ ., data = x.tr)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;    Min     1Q Median     3Q    Max </span>
<span class="co">#&gt; -66.06 -14.11  -0.78  17.13  66.09 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)  2.210e+03  5.091e+02   4.341 0.000157 ***</span>
<span class="co">#&gt; PREC         1.786e+00  1.306e+00   1.367 0.181994    </span>
<span class="co">#&gt; JANT        -1.794e+00  1.205e+00  -1.489 0.147375    </span>
<span class="co">#&gt; JULT        -4.767e+00  2.913e+00  -1.636 0.112591    </span>
<span class="co">#&gt; OVR65       -1.150e+01  9.335e+00  -1.232 0.227734    </span>
<span class="co">#&gt; POPN        -1.586e+02  7.373e+01  -2.151 0.039980 *  </span>
<span class="co">#&gt; EDUC        -1.278e+01  1.421e+01  -0.899 0.376043    </span>
<span class="co">#&gt; HOUS        -8.500e-01  2.013e+00  -0.422 0.676023    </span>
<span class="co">#&gt; DENS         8.253e-03  5.274e-03   1.565 0.128473    </span>
<span class="co">#&gt; NONW         4.844e+00  1.566e+00   3.093 0.004357 ** </span>
<span class="co">#&gt; WWDRK       -1.666e-01  1.947e+00  -0.086 0.932408    </span>
<span class="co">#&gt; POOR        -1.755e+00  3.530e+00  -0.497 0.622938    </span>
<span class="co">#&gt; HC          -4.090e-01  5.452e-01  -0.750 0.459193    </span>
<span class="co">#&gt; NOX          5.607e-01  1.109e+00   0.506 0.616884    </span>
<span class="co">#&gt; SO.          1.762e-01  1.848e-01   0.954 0.348033    </span>
<span class="co">#&gt; HUMID       -2.647e+00  2.160e+00  -1.225 0.230307    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 32.55 on 29 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.7978, Adjusted R-squared:  0.6931 </span>
<span class="co">#&gt; F-statistic: 7.626 on 15 and 29 DF,  p-value: 1.805e-06</span></code></pre></div>
<p>The fit appears to be routine, and reasonable (why? what did I check to come to this conclusion?).</p>
<div id="a-new-focus-prediction" class="section level3">
<h3>
<span class="header-section-number">1.0.1</span> A new focus: prediction<a class="anchor" aria-label="anchor" href="#a-new-focus-prediction"><i class="fas fa-link"></i></a>
</h3>
<p>This course will be primarily concerned with making (good) predictions for cases
(data points) that we may have not observed yet (future predictions). This is a bit
different from the focus of other Statistics courses you may have taken. You will
see later in the course that what you learned in other Statistics courses
(e.g. trade-offs between flexibility and stability of different models, uncertainty
and standard techniques to reduce it, etc.) will prove
to be critical for building good predictions.</p>
<p>As a simple example, in the rest of this note we will compare the quality of this model’s predictions with those of a simpler (smaller) linear model with only 5 predictors. For this illustrative example, we will not worry about how these 5 explanatory variables were selected, however, this will play a <strong>critical</strong> role later in the course).</p>
<p>We now fit this <strong>reduced</strong> model and look at the estimated parameters and diagnostic plots</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">MORT</span> <span class="op">~</span> <span class="va">POOR</span> <span class="op">+</span> <span class="va">HC</span> <span class="op">+</span> <span class="va">NOX</span> <span class="op">+</span> <span class="va">HOUS</span> <span class="op">+</span> <span class="va">NONW</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = MORT ~ POOR + HC + NOX + HOUS + NONW, data = x.tr)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -95.654 -21.848  -1.995  21.555  81.039 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept) 1117.2254   164.3972   6.796 4.09e-08 ***</span>
<span class="co">#&gt; POOR          -4.7667     2.5516  -1.868 0.069268 .  </span>
<span class="co">#&gt; HC            -1.4237     0.3705  -3.843 0.000437 ***</span>
<span class="co">#&gt; NOX            2.6880     0.7262   3.702 0.000660 ***</span>
<span class="co">#&gt; HOUS          -2.0595     1.7940  -1.148 0.257957    </span>
<span class="co">#&gt; NONW           4.3004     1.0140   4.241 0.000132 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 39.44 on 39 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.6007, Adjusted R-squared:  0.5495 </span>
<span class="co">#&gt; F-statistic: 11.73 on 5 and 39 DF,  p-value: 5.844e-07</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">reduced</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="02-lm-diagnostics-review_files/figure-html/reduced-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">reduced</span>, which <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="02-lm-diagnostics-review_files/figure-html/reduced-2.png" width="90%" style="display: block; margin: auto;"></div>
<p>Although the reduced linear model (with 5 predictors) does not seem to provide a fit
as good as the one we get with full model, it is still acceptable.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; [1] 60652.22</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">full</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; [1] 30718.19</span></code></pre></div>
<p>This observation should be obvious to you, since,
as you already now, a model will <strong>always</strong> yield
a better fit to the data in terms of
residual sum of squares than any of its submodels
(i.e. any model using a subset of the explanatory
variables). I expect you to be able to formally
prove the last satement.</p>
<p>Our question of interest here is:
“Which model produces better predictions?” In many cases one is
interested in predicting future observations, i.e. 
predicting the response variable for data
that was not available when the model / predictor was
<em>fit</em> or <em>trained</em>. As we discussed in class, a reasonably
fair comparison can be obtined by
comparing the mean squared predictions
of these two linear models on the test set, which we
read into <code>R</code> as follows:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x.te</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/pollution-test.dat"</span>, header <span class="op">=</span> <span class="cn">TRUE</span>, sep <span class="op">=</span> <span class="st">","</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">x.te</span><span class="op">)</span>
<span class="co">#&gt;   PREC JANT JULT OVR65 POPN EDUC HOUS DENS NONW WWDRK POOR HC NOX SO. HUMID</span>
<span class="co">#&gt; 1   52   42   79   7.7 3.39  9.6 69.2 2302 22.2  41.3 24.2 18   8  27    56</span>
<span class="co">#&gt; 2   33   26   76   8.6 3.20 10.9 83.4 6122 16.3  44.9 10.7 88  63 278    58</span>
<span class="co">#&gt; 3   40   34   77   9.2 3.21 10.2 77.0 4101 13.0  45.7 15.1 26  26 146    57</span>
<span class="co">#&gt; 4   35   46   85   7.1 3.22 11.8 79.9 1441 14.8  51.2 16.1  1   1   1    54</span>
<span class="co">#&gt; 5   15   30   73   8.2 3.15 12.2 84.2 4824  4.7  53.1 12.7 17   8  28    38</span>
<span class="co">#&gt; 6   43   27   72   9.0 3.25 11.5 87.1 2909  7.2  51.6  9.5  7   3  10    56</span>
<span class="co">#&gt;       MORT</span>
<span class="co">#&gt; 1 1017.613</span>
<span class="co">#&gt; 2 1024.885</span>
<span class="co">#&gt; 3  970.467</span>
<span class="co">#&gt; 4  860.101</span>
<span class="co">#&gt; 5  871.766</span>
<span class="co">#&gt; 6  887.466</span></code></pre></div>
<p>Now compute the predicted values for the test set
with both the <strong>full</strong> and <strong>reduced</strong> models:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x.te</span><span class="op">$</span><span class="va">pr.full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">full</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span>
<span class="va">x.te</span><span class="op">$</span><span class="va">pr.reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reduced</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span></code></pre></div>
<p>and compute the corresponding mean squared prediction errors:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">x.te</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">MORT</span> <span class="op">-</span> <span class="va">pr.full</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 2859.367</span>
<span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">x.te</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">MORT</span> <span class="op">-</span> <span class="va">pr.reduced</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 1861.884</span></code></pre></div>
<p>Note that the reduced model (that did not fit the data
as well as the full model) nevertheless produced
better predictions (smaller mean squared prediction
errors) on the test set.</p>
<p>At this point you should put on your critical / skeptical
hat and wonder if this did not happen <em>by chance</em>, i.e.
if this may be just
an artifact of the specific training/test partition
we used. The following simple experiment shows that
this is not the case. It would be a <strong>very good exercise</strong>
for you to repeat it many times (100, say) to verify
my claim.</p>
<p>First, read the whole data and create a new
training / test random split.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># repeat with different partitions</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"data/rutgers-lib-30861_CSV-1.csv"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">456</span><span class="op">)</span>
<span class="va">ii</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, each <span class="op">=</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span>
<span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="fl">2</span>, <span class="op">]</span>
<span class="va">x.te</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span></code></pre></div>
<p>In the above code chunk, I used <code>x.tr</code> to denote the
training set and <code>x.te</code> for the test set.
Now, fit the full and reduced models
on this new training set:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">MORT</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span>
<span class="va">reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">MORT</span> <span class="op">~</span> <span class="va">POOR</span> <span class="op">+</span> <span class="va">HC</span> <span class="op">+</span> <span class="va">NOX</span> <span class="op">+</span> <span class="va">HOUS</span> <span class="op">+</span> <span class="va">NONW</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span></code></pre></div>
<p>Finally, estimate the mean squared prediction
error of these models with their squared prediction
error on the test set:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x.te</span><span class="op">$</span><span class="va">pr.full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">full</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span>
<span class="va">x.te</span><span class="op">$</span><span class="va">pr.reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reduced</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">x.te</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">MORT</span> <span class="op">-</span> <span class="va">pr.full</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 2194.79</span>
<span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">x.te</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">MORT</span> <span class="op">-</span> <span class="va">pr.reduced</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 1393.885</span></code></pre></div>
<p>Note that the estimated mean squared prediction error
of the reduced model is again considerably smaller
than that of the full model (even though the latter always fits the
training set better than the reduced one).</p>

</div>
</div>



  <div class="chapter-nav">
<div class="prev"><a href="preface.html">Preface</a></div>
<div class="next"><a href="predictions-using-a-linear-model-continued.html"><span class="header-section-number">2</span> Predictions using a linear model (continued)</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li>
<a class="nav-link" href="#predictions-using-a-linear-model"><span class="header-section-number">1</span> Predictions using a linear model</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#a-new-focus-prediction"><span class="header-section-number">1.0.1</span> A new focus: prediction</a></li></ul>
</li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/ubc-stat/stat-406-worksheets/blob/main/02-lm-diagnostics-review.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/ubc-stat/stat-406-worksheets/edit/main/02-lm-diagnostics-review.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>UBC Stat 406 Worksheets</strong>" was written by Daniel J. McDonald and Matías Salibán-Barrera. It was last built on 2021-09-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
