{
  "hash": "41f7740c8fa31defddf6aef0f32cb75d",
  "result": {
    "markdown": "# Bagging for regression\n\n\n\n\n\n\nOne strategy to obtain more stable predictors is called\n**Bootstrap AGGregatING** (bagging). It can be applied to\nmany predictors (not only trees), and it generally results\nin larger improvements in prediction quality when it is used with predictors\nthat are flexible (low bias), but highly variable.\n\nThe justification and motivation were discussed in class. Intuitively\nwe are averaging the predictions obtained from an estimate of the \n\"average prediction\" we would have computed had we had access to \nseveral (many?) independent training sets (samples). \n\nThere are several (many?) `R` packages implementing\nbagging for different predictors, with varying degrees of \nflexibility (the implementations) and user-friendliness. \nHowever, for pedagogical and illustrative purposes, in these notes I will\n**bagg** by hand.\n\n### Bagging by hand\n\nAgain, to simplify the discussion and presentation, in order to evaluate \nprediction quality I will split the \ndata (`Boston`) into a training and a test set. We do this now:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1_bb1251edc50fc19595734098dfff1668'}\n\n```{.r .cell-code}\nlibrary(rpart)\ndata(Boston, package = \"MASS\")\nset.seed(123456)\nn <- nrow(Boston)\nii <- sample(n, floor(n / 4))\ndat.te <- Boston[ii, ]\ndat.tr <- Boston[-ii, ]\n```\n:::\n\nI will now train $N = 5$ trees and average their predictions. \nNote that, in order to illustrate the process more\nclearly, I will compute and store the $n_e \\times N$\npredictions in a two-dimensional array (aka a matrix), \nwhere $n_e$ denotes the number of observations in \nthe test set. This is not the best (i.e. most efficient) way of implementing **bagging**,\nbut the main purpose here is to understand **exactly what** we are doing. Also note that\nan alternative (better in terms of reusability of the\nensemble, but maybe still not the most efficient option) is\nto store the $N$ trees directly. This will also allow for\nmore elegant and easy to read code, and it is \nillustrated below, but first we will use the \nthe former (and hopefully clearer) strategy.\n\nFirst create an array where we will store all the predictions:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag2_eed323c4364e2904fe52d53dae8ae08d'}\n\n```{.r .cell-code}\nN <- 5\nmyps <- array(NA, dim = c(nrow(dat.te), N))\ncon <- rpart.control(minsplit = 3, cp = 1e-3, xval = 1)\n```\n:::\n\nThe last object (`con`) contains my options to train large\n(potentially overfitting) trees. \nAs discussed in class, we now generate `N` bootstrap samples \nby generating vectors of randomly sampled indices (with replacement), the\nrelevant lines of code are:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag03_4629636be92caf121cee2e66d616c295'}\n\n```{.r .cell-code}\nii <- sample(n.tr, replace = TRUE)\ntmp <- rpart(..., data = dat.tr[ii, ], ...)\n```\n:::\n\nwhere we train the trees on the data set `dat.tr[ii, ]`, which is the boostrap sample.\nThen, for each of these trees we compute the corresponding (vector of) predictions on the \ntest set (`predict(tmp, newdata=dat.te, type='vector')`) and store them. \nPutting all the pieces together we get:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag3_7949e77f263e87cd2a9fe0d3ca4ae421'}\n\n```{.r .cell-code}\nn.tr <- nrow(dat.tr)\nset.seed(123)\nfor (j in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  tmp <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n  myps[, j] <- predict(tmp, newdata = dat.te, type = \"vector\")\n}\n```\n:::\n\nThe bagged predictions are the average of the predictions obtained with each tree in the\nensamble. In other words, for each point in `dat.te` we need to compute the average of the \npredictions obtained with the `N` different trees. Because of the way\nI stored the results in the matrix `myps`, the bagged prediction of each point in\n`dat.te` is the average of the corresponding row in the matrix `myps`. We can compute\nall these ($n_e$) averages at once using `rowMeans()` as follows:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag32_112640907a5655a51e274b6cd3a63d70'}\n\n```{.r .cell-code}\npr.bagg <- rowMeans(myps)\n```\n:::\n\nFinally, the estimated MSPE of the bagged ensemble of trees obtained with our specific\ntest set is:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag33_183abb16c9d319c0bed6106b022aff72'}\n\n```{.r .cell-code}\nwith(dat.te, mean((medv - pr.bagg)^2))\n#> [1] 14.54751\n```\n:::\n\nWe can now compare this with the similarly estimated\nMSPE of the pruned tree: \n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag4_7f004b38e9cc0f8f26cf7f46c83f7348'}\n\n```{.r .cell-code}\nmyc <- rpart.control(minsplit = 2, cp = 1e-5, xval = 10)\nset.seed(123456)\nbos.to <- rpart(medv ~ .,\n  data = dat.tr, method = \"anova\",\n  control = myc\n)\nb <- bos.to$cptable[which.min(bos.to$cptable[, \"xerror\"]), \"CP\"]\nbos.t3 <- prune(bos.to, cp = b)\npr.t3 <- predict(bos.t3, newdata = dat.te, type = \"vector\")\nwith(dat.te, mean((medv - pr.t3)^2))\n#> [1] 16.59113\n```\n:::\n\nWould the quality of the bagged predictions improve if we use \na larger ensemble? For example, what happens if we **bagg** $N = 10$ trees? \n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag10_5fcf854514e66c1a1ca350533a06a37f'}\n\n```{.r .cell-code}\nN <- 10\nmyps <- array(NA, dim = c(nrow(dat.te), N))\nn.tr <- nrow(dat.tr)\nset.seed(123)\nfor (j in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  tmp <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n  myps[, j] <- predict(tmp, newdata = dat.te, type = \"vector\")\n}\npr.bagg <- rowMeans(myps)\nwith(dat.te, mean((medv - pr.bagg)^2))\n#> [1] 13.97641\n```\n:::\n\nor $N = 100$ trees? \n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag100_c8de517d59817f7e80f209299e4bbc40'}\n\n```{.r .cell-code}\nN <- 100\nmyps <- array(NA, dim = c(nrow(dat.te), N))\nn.tr <- nrow(dat.tr)\nset.seed(123)\nfor (j in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  tmp <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n  myps[, j] <- predict(tmp, newdata = dat.te, type = \"vector\")\n}\npr.bagg <- rowMeans(myps)\nwith(dat.te, mean((medv - pr.bagg)^2))\n#> [1] 12.10982\n```\n:::\n\nor $N = 1000$ trees? \n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000_92c5f14e2b77418e6c98a75b24c6e284'}\n\n```{.r .cell-code}\nN <- 1000\nmyps <- array(NA, dim = c(nrow(dat.te), N))\nn.tr <- nrow(dat.tr)\nset.seed(123)\nfor (j in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  tmp <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n  myps[, j] <- predict(tmp, newdata = dat.te, type = \"vector\")\n}\npr.bagg <- rowMeans(myps)\nwith(dat.te, mean((medv - pr.bagg)^2))\n#> [1] 11.48381\n```\n:::\n\n\nNote that, at least for this test set, increasing the number of bagged trees\nseems to improve the MSPE. However, the gain appears to decrease, so it may\nnot be worth the computational effort to use a larger **bag** / ensemble. \nFurthermore, one may also want to investigate whether this is an\nartifact of this specific training / test partition, or if similar\npatterns of MSPE are observed for other random training / test splits. \nBelow we try a different test/training split and repeat the \nbagging experiment above: \n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/anothersplit_776a2c4207af7c625f9b8e70f46879d5'}\n\n```{.r .cell-code}\nset.seed(1234)\nn <- nrow(Boston)\nii <- sample(n, floor(n / 4))\ndat.te <- Boston[ii, ]\ndat.tr <- Boston[-ii, ]\nNs <- c(5, 10, 100, 1000)\nall.results <- matrix(NA, length(Ns), 2)\ncolnames(all.results) <- c(\"N\", \"MSPE\")\nn.tr <- nrow(dat.tr)\nfor (hh in 1:length(Ns)) {\n  N <- Ns[hh]\n  myps <- array(NA, dim = c(nrow(dat.te), N))\n  set.seed(123)\n  for (j in 1:N) {\n    ii <- sample(n.tr, replace = TRUE)\n    tmp <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n    myps[, j] <- predict(tmp, newdata = dat.te, type = \"vector\")\n  }\n  pr.bagg <- rowMeans(myps)\n  all.results[hh, ] <- c(N, with(dat.te, mean((medv - pr.bagg)^2)))\n}\nprint(all.results)\n#>         N     MSPE\n#> [1,]    5 18.27651\n#> [2,]   10 17.50426\n#> [3,]  100 14.52966\n#> [4,] 1000 14.27511\n```\n:::\n\nThe pattern is in fact similar to the one we observed before: \nincreasing the size of the ensemble $N$ helps, but the improvements \nbecome smaller after a certain value of $N$. \nYou are **strongly encouraged** to verify this by repeating the above experiment \nwith different train/test splits. Furthermore, a **very good exercise** is to explore \nwhat happens with the MSPE of the bagged ensembles (for different values of $N$) \nwhen the MSPE is estimated using cross-validation\n(instead of using a specific test set). Do it!\n\n\n## More efficient, useful and elegant implementation  \n\nI will now illustrate a possibly more efficient way to implement bagging, namely\nstoring the $N$ trees (rather than their predictions on a given data set).\nIn this way one can re-use the ensemble (on any future data set) without\nhaving to re-train the elements of the **bag**. Since the idea is \nthe same, I will just do it for ensemble of $N = 100$ trees. \nTo simplify the comparison between this implementation of\nbagging and the one used above, we first re-create\nthe original training / test split\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000.alt0_a0898d1a9a8ae0093468d85145b2cdad'}\n\n```{.r .cell-code}\nset.seed(123456)\nn <- nrow(Boston)\nii <- sample(n, floor(n / 4))\ndat.te <- Boston[ii, ]\ndat.tr <- Boston[-ii, ]\n```\n:::\n\nNow, let's create a `list` of 100 (empty) elements, each element of this \nlist will store a regression tree:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000.alt_8e3d20012531820571a09249f024aace'}\n\n```{.r .cell-code}\nN <- 100\nmybag <- vector(\"list\", N)\n```\n:::\n\nNow, we train the $N$ trees as before, but store them in the `list` (without\ncomputing any predictions):\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000.alt2_3d34714d8b4485f93425420dd6199c8a'}\n\n```{.r .cell-code}\nset.seed(123)\nfor (j in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  mybag[[j]] <- rpart(medv ~ ., data = dat.tr[ii, ], method = \"anova\", control = con)\n}\n```\n:::\n\nGiven a new data set, in order to obtain the corresponding predictions for \neach tree in the ensemble, one could either:\n\n* loop over the $N$ trees, averaging the corresponding $N$ vectors of predictions; or\n* use `sapply` (check the help page if you are not familiar with the `apply` functions in `R`).\n\nThe later option results in code that is much more elegant, \nefficient (allowing for future uses of the ensemble),\nand compact. Of course both give exactly the same results. Below \nwe illustrate both strategies. If we use the **first approach (loop)**\nwe obtain the following estimated MSPE using the test set:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000.alt3_d414559d189a623a86ad45f752d19d21'}\n\n```{.r .cell-code}\npr.bagg2 <- rep(0, nrow(dat.te))\nfor (j in 1:N) {\n  pr.bagg2 <- pr.bagg2 + predict(mybag[[j]], newdata = dat.te) / N\n}\nwith(dat.te, mean((medv - pr.bagg2)^2))\n#> [1] 12.10982\n```\n:::\n\n(compare it with the results we obtained before). Using the **second approach (sapply)**:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bag1000.alt4_4d04e86da7e429f9843c28cd66eb0ca3'}\n\n```{.r .cell-code}\npr.bagg3 <- rowMeans(sapply(mybag, predict, newdata = dat.te))\nwith(dat.te, mean((medv - pr.bagg3)^2))\n#> [1] 12.10982\n```\n:::\n\nBoth results are of course identical. \n\n\n## Bagging a regression spline\n\nBagging does not provide much of an advantage when applied to linear\npredictors (can you explain why?) Nevertheless, let us try it on the `lidar` data, \nwhich, as we did before, we randomly split into a training and test set:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bagsplines_c8f92b33dcf1591cffb9a3a18afb2888'}\n\n```{.r .cell-code}\ndata(lidar, package = \"SemiPar\")\nset.seed(123456)\nn <- nrow(lidar)\nii <- sample(n, floor(n / 5))\nlid.te <- lidar[ii, ]\nlid.tr <- lidar[-ii, ]\n```\n:::\n\nNow fit a cubic spline, and estimate the MSPE using the test set:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bagsplines2_8d45ff9a6bd272adbcdd645827d8b1d8'}\n\n```{.r .cell-code}\nlibrary(splines)\na <- lm(logratio ~ bs(x = range, df = 10, degree = 3), data = lid.tr)\noo <- order(lid.tr$range)\npr.of <- predict(a, newdata = lid.te)\nmean((lid.te$logratio - pr.of)^2)\n#> [1] 0.007427559\n```\n:::\n\nWe build an ensemble of 10 fits and estimate the corresponding\nMSPE using the test set:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bagsplines3_8b7029a5247269855071c414c2b14b96'}\n\n```{.r .cell-code}\nN <- 10\nmyps <- matrix(NA, nrow(lid.te), N)\nset.seed(123)\nn.tr <- nrow(lid.tr)\nfor (i in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  a.b <- lm(logratio ~ bs(x = range, df = 10, degree = 3), data = lid.tr[ii, ])\n  myps[, i] <- predict(a.b, newdata = lid.te)\n}\npr.ba <- rowMeans(myps) # , na.rm=TRUE)\nmean((lid.te$logratio - pr.ba)^2)\n#> [1] 0.007552562\n```\n:::\n\nNote that the estimated MSPE is almost the same as the one of the \noriginal single spline. \nFurthermore, adding more elements to the ensemble does not seem to improve the \nestimated MSPEs:\n\n::: {.cell layout-align=\"center\" hash='40-bagging_cache/html/bagsplines4_f5e53459cd668de2c9fd25de9bac4913'}\n\n```{.r .cell-code}\nN <- 100\nmyps <- matrix(NA, nrow(lid.te), N)\nset.seed(123)\nn.tr <- nrow(lid.tr)\nfor (i in 1:N) {\n  ii <- sample(n.tr, replace = TRUE)\n  a.b <- lm(logratio ~ bs(x = range, df = 10, degree = 3), data = lid.tr[ii, ])\n  myps[, i] <- predict(a.b, newdata = lid.te)\n}\npr.ba <- rowMeans(myps) # , na.rm=TRUE)\nmean((lid.te$logratio - pr.ba)^2)\n#> [1] 0.0075887\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}