<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>22 Model based clustering | UBC Stat 406 Worksheets</title>
<meta name="author" content="Daniel J. McDonald and Matías Salibán-Barrera">
<meta name="description" content="Model-based clustering methods depend on a probabilistic model that specifies the distribution of the observed features (over the whole population). This distribution is typically modelled as a...">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="22 Model based clustering | UBC Stat 406 Worksheets">
<meta property="og:type" content="book">
<meta property="og:url" content="https://ubc-stat.github.io/stat-406-worksheets/model-based-clustering.html">
<meta property="og:description" content="Model-based clustering methods depend on a probabilistic model that specifies the distribution of the observed features (over the whole population). This distribution is typically modelled as a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="22 Model based clustering | UBC Stat 406 Worksheets">
<meta name="twitter:description" content="Model-based clustering methods depend on a probabilistic model that specifies the distribution of the observed features (over the whole population). This distribution is typically modelled as a...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">UBC Stat 406 Worksheets</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Stat 406 Worksheets</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Module 0 – Review</li>
<li><a class="" href="predictions-using-a-linear-model.html"><span class="header-section-number">1</span> Predictions using a linear model</a></li>
<li class="book-part">Module 1 – Model Selection</li>
<li><a class="" href="predictions-using-a-linear-model-continued.html"><span class="header-section-number">2</span> Predictions using a linear model (continued)</a></li>
<li><a class="" href="cross-validation-concerns.html"><span class="header-section-number">3</span> Cross-validation concerns</a></li>
<li><a class="" href="comparing-models.html"><span class="header-section-number">4</span> Comparing models</a></li>
<li class="book-part">Module 2 – Regression</li>
<li><a class="" href="ridge-regression.html"><span class="header-section-number">5</span> Ridge regression</a></li>
<li><a class="" href="lasso.html"><span class="header-section-number">6</span> LASSO</a></li>
<li><a class="" href="non-parametric-regression.html"><span class="header-section-number">7</span> Non-parametric regression</a></li>
<li><a class="" href="kernel-regression-local-regression.html"><span class="header-section-number">8</span> Kernel regression / local regression</a></li>
<li><a class="" href="regression-trees.html"><span class="header-section-number">9</span> Regression trees</a></li>
<li><a class="" href="pruning-regression-trees-with-rpart.html"><span class="header-section-number">10</span> Pruning regression trees with rpart</a></li>
<li class="book-part">Module 3 – Classification</li>
<li><a class="" href="parametric-classifiers.html"><span class="header-section-number">11</span> Parametric classifiers</a></li>
<li><a class="" href="qda.html"><span class="header-section-number">12</span> QDA</a></li>
<li><a class="" href="classification-trees.html"><span class="header-section-number">13</span> Classification Trees</a></li>
<li class="book-part">Module 4 – Modern techniques</li>
<li><a class="" href="bagging-for-regression.html"><span class="header-section-number">14</span> Bagging for regression</a></li>
<li><a class="" href="bagging-for-classification.html"><span class="header-section-number">15</span> Bagging for classification</a></li>
<li><a class="" href="random-forests.html"><span class="header-section-number">16</span> Random Forests</a></li>
<li><a class="" href="boosting-a-statistical-learning-perspective.html"><span class="header-section-number">17</span> Boosting (a Statistical Learning perspective)</a></li>
<li><a class="" href="what-is-adaboost-doing-really.html"><span class="header-section-number">18</span> What is Adaboost doing, really?</a></li>
<li><a class="" href="single-layer-neural-network.html"><span class="header-section-number">19</span> Single layer neural network</a></li>
<li class="book-part">Module 5 – Unsupervised learning</li>
<li><a class="" href="introduction.html"><span class="header-section-number">20</span> Introduction</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">21</span> Clustering</a></li>
<li><a class="active" href="model-based-clustering.html"><span class="header-section-number">22</span> Model based clustering</a></li>
<li><a class="" href="hierarchical-clustering.html"><span class="header-section-number">23</span> Hierarchical clustering</a></li>
<li><a class="" href="references.html">References</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="alt-pca.html"><span class="header-section-number">A</span> PCA and alternating regression</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/ubc-stat/stat-406-worksheets">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="model-based-clustering" class="section level1">
<h1>
<span class="header-section-number">22</span> Model based clustering<a class="anchor" aria-label="anchor" href="#model-based-clustering"><i class="fas fa-link"></i></a>
</h1>
<p>Model-based clustering methods depend on a probabilistic
model that specifies the distribution of the observed features
(over the whole population). This distribution is
typically modelled as a mixture of several
different distributions. Given a sample of <em>n</em> vectors of
features <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, …, <span class="math inline">\(X_n\)</span>, the clustering problem then becomes
the estimation of the <em>n</em> unobserved labels that indicate to which
sub-population (cluster, group) each <span class="math inline">\(X_i\)</span> belongs. In addition,
one generally also has to estimate the parameters that specify the
distribution of <span class="math inline">\(X\)</span> in each assumed group.</p>
<p>Given that this method is based on a full specificification of
the distribution of the observed vector of features, it is not
surprising that the parameters are generally estimated using maximum
likelihood. The difficulty is that there are <em>n</em> unobserved (missing)
variables (the group labels) that also need to be estimated (<em>imputed</em>).
The most commonly used approach uses the EM algorithm to
perform maximum likelihood estimation with missing observations.</p>
<div id="em-algorithm" class="section level2">
<h2>
<span class="header-section-number">22.1</span> EM algorithm<a class="anchor" aria-label="anchor" href="#em-algorithm"><i class="fas fa-link"></i></a>
</h2>
<p>The specifics of the EM algorithm were introduced and discussed in
class. Although the algorithm may seem clear at first sight,
it is fairly subtle, and mistakes and misunderstandings are
very (<strong>very</strong>) common. Many applications of the EM algorithm
found on-line are either wrong, or wrongly derived.
For a more detailed discussion and a different
(and also very useful) application of the algorithm, see the
Section <strong>Imputation via EM</strong> below.</p>
</div>
<div id="bivariate-gaussian-mixture-model-via-em-by-hand" class="section level2">
<h2>
<span class="header-section-number">22.2</span> Bivariate Gaussian mixture model via EM “by hand”<a class="anchor" aria-label="anchor" href="#bivariate-gaussian-mixture-model-via-em-by-hand"><i class="fas fa-link"></i></a>
</h2>
<p>We will use a 2-dimensional representation of the
UN votes data. This lower-dimensional representation
is obtained using multidimensional scaling, a topic
we will cover later in the course. For formulas
and specific steps of the algorithm please refer
to your class notes.
We first load the data and reduce it to a 2-dimensional
problem, in order to be able to plot the results.
It will be a very nice exercise for the reader to
re-do this analysis on the original data set.</p>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span>file <span class="op">=</span> <span class="st">"data/unvotes.csv"</span>, sep <span class="op">=</span> <span class="st">","</span>, row.names <span class="op">=</span> <span class="fl">1</span>, header <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co"># Compute pairwise distances and use MDS</span>
<span class="va">dd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span>
<span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cmdscale.html">cmdscale</a></span><span class="op">(</span><span class="va">dd</span>, k <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<p>This is the data with which we will work:</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/scatter-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We will now use the EM algorithm to find (Gaussian-ly
distributed) clusters in the data. First
we find initial maximum likelihood estimators (i.e. initial
values for the EM algorithm), using a random
partition of the data:</p>
<div class="sourceCode" id="cb327"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">3</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">tmp</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123456</span><span class="op">)</span>
<span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span> <span class="op">%%</span> <span class="va">k</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">gammas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span>, <span class="va">k</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="va">gammas</span><span class="op">[</span><span class="va">b</span> <span class="op">==</span> <span class="va">j</span>, <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span>
<span class="va">pis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span>
<span class="va">mus</span> <span class="op">&lt;-</span> <span class="va">sigmas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"list"</span>, <span class="va">k</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">mus</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">tmp</span> <span class="op">*</span> <span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span>
  <span class="va">sigmas</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">tmp</span> <span class="op">*</span> <span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">tmp</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Note that the above loop could have been computed more efficiently
using the fact that at the initial
step the gamma coefficients are either 0’s or 1’s.
However, in the following steps of the EM algorithm we will
need to use such <em>weighted averages</em> computations, since
in general the weights are between 0 and 1.</p>
<p>This is the initial configuration (pure noise):</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/initial.scatter-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We now launch our iterations. Here I run 120 iterations. Can you
think of an appropriate convergence criterion? Should
we look at the parameter
estimates, the gammas (posterior class probabilities),
the likelihood function?</p>
<div class="sourceCode" id="cb328"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://mvtnorm.R-forge.R-project.org">mvtnorm</a></span><span class="op">)</span>
<span class="va">niter</span> <span class="op">&lt;-</span> <span class="fl">120</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">niter</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># E step</span>
  <span class="co"># compute posterior probabilites f(x_i, \theta^k)</span>
  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">tmp</span>, <span class="fl">1</span>, <span class="va">dmvnorm</span>, mean <span class="op">=</span> <span class="va">mus</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span>, 
                         sigma <span class="op">=</span> <span class="va">sigmas</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
  <span class="op">}</span>
  <span class="co"># multiply by probs of each class</span>
  <span class="co"># f(x_i, \theta^k) * pi_k</span>
  <span class="va">gammas</span> <span class="op">&lt;-</span> <span class="va">gammas</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">pis</span><span class="op">)</span>
  <span class="co"># standardize: f(x_i, \theta^k) * pi_k / [ sum_s { f(x_i, \theta^s) * pi_s } ]</span>
  <span class="va">gammas</span> <span class="op">&lt;-</span> <span class="va">gammas</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">)</span>
  <span class="co"># M step</span>
  <span class="co"># the maximizers of the expected likelihood have</span>
  <span class="co"># a closed form in the Gaussian case, they are</span>
  <span class="co"># just weighted means and covariance matrices</span>
  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">mus</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">tmp</span> <span class="op">*</span> <span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span>
    <span class="va">tmp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">tmp</span>, scale <span class="op">=</span> <span class="cn">FALSE</span>, center <span class="op">=</span> <span class="va">mus</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
    <span class="va">sigmas</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">tmp2</span> <span class="op">*</span> <span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">tmp2</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span><span class="op">)</span>
  <span class="op">}</span>
  <span class="co"># update pi's</span>
  <span class="va">pis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">gammas</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span> <span class="co"># n = sum(colSums(gammas))</span>
<span class="op">}</span></code></pre></div>
<p>We now plot the estimated density for X, which is
a combination of 3 gaussian densities.
We do this by evaluating the estimated densities
on a relatively fine grid of points and displaying them.
We will color the points according to the estimated
group labels (the largest estimated posterior
probability for each point). We first compute those</p>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># estimated groups</span>
<span class="va">emlab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">gammas</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span>
<span class="co"># build a 100 x 100 grid</span>
<span class="va">ngr</span> <span class="op">&lt;-</span> <span class="fl">100</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">15</span>, <span class="fl">15</span>, length <span class="op">=</span> <span class="va">ngr</span><span class="op">)</span>
<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>, <span class="fl">7</span>, length <span class="op">=</span> <span class="va">ngr</span><span class="op">)</span>
<span class="va">xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span><span class="op">)</span>
<span class="co"># evaluate each density component on each grid point</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">ngr</span> <span class="op">*</span> <span class="va">ngr</span>, <span class="va">k</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">m</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">xx</span>, <span class="fl">1</span>, <span class="va">dmvnorm</span>, mean <span class="op">=</span> <span class="va">mus</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span>, sigma <span class="op">=</span> <span class="va">sigmas</span><span class="op">[[</span><span class="va">j</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="op">}</span>
<span class="co"># apply weights</span>
<span class="va">mm</span> <span class="op">&lt;-</span> <span class="va">m</span> <span class="op">%*%</span> <span class="va">pis</span> <span class="co"># apply(m, 1, max)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/filled.contour.html">filled.contour</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">mm</span>, <span class="va">ngr</span>, <span class="va">ngr</span><span class="op">)</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">35</span><span class="op">)</span>,
  xlab <span class="op">=</span> <span class="st">""</span>, ylab <span class="op">=</span> <span class="st">""</span>,
  panel.last <span class="op">=</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">tmp</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">tmp</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"red"</span>, <span class="st">"darkblue"</span><span class="op">)</span><span class="op">[</span><span class="va">emlab</span><span class="op">]</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/displ1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We can also show each separate estimated component:</p>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m2</span> <span class="op">&lt;-</span> <span class="va">m</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">pis</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/graphics/filled.contour.html">filled.contour</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">m2</span><span class="op">[</span>, <span class="va">j</span><span class="op">]</span>, <span class="va">ngr</span>, <span class="va">ngr</span><span class="op">)</span>,
    col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">35</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">""</span>, ylab <span class="op">=</span> <span class="st">""</span>,
    panel.last <span class="op">=</span> <span class="op">{</span>
      <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">tmp</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">tmp</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"red"</span>, <span class="st">"darkblue"</span><span class="op">)</span><span class="op">[</span><span class="va">emlab</span><span class="op">]</span><span class="op">)</span>
    <span class="op">}</span>
  <span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p><img src="53-model-based-clustering_files/figure-html/sep.dens-1.png" width="90%" style="display: block; margin: auto;"><img src="53-model-based-clustering_files/figure-html/sep.dens-2.png" width="90%" style="display: block; margin: auto;"><img src="53-model-based-clustering_files/figure-html/sep.dens-3.png" width="90%" style="display: block; margin: auto;"></p>
</div>
<div id="model-assumptions-may-be-important" class="section level2">
<h2>
<span class="header-section-number">22.3</span> Model assumptions may be important<a class="anchor" aria-label="anchor" href="#model-assumptions-may-be-important"><i class="fas fa-link"></i></a>
</h2>
<p>We will illustrate the problem with a synthetic data set.
There are 3 groups with 300 observations in each,
and 3 variables / features.</p>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># sample size</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">300</span>

<span class="co"># covariance matrices for two of the groups</span>
<span class="va">s1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">3</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">s2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">0</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">4</span>, <span class="fl">3</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">3</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">s1.sqrt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/chol.html">chol</a></span><span class="op">(</span><span class="va">s1</span><span class="op">)</span>
<span class="va">s2.sqrt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/chol.html">chol</a></span><span class="op">(</span><span class="va">s2</span><span class="op">)</span>

<span class="co"># easy case, well separated groups</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">31</span><span class="op">)</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">s1.sqrt</span>
<span class="va">mu2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">8</span>, <span class="fl">3</span><span class="op">)</span>
<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">s2.sqrt</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu2</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">mu3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">10</span><span class="op">)</span>
<span class="va">x3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu3</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="va">x3</span><span class="op">)</span></code></pre></div>
<p>This is how the data look</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/disp.noise1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>It is not a surprise that model-based clustering works
very well in this case:</p>
<div class="sourceCode" id="cb332"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mclust-org.github.io/mclust/">mclust</a></span><span class="op">)</span>
<span class="co"># select the number of clusters using likelihood-base criterion</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="co"># show the data, color-coded according to the groups found</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x</span>, col <span class="op">=</span> <span class="va">m</span><span class="op">$</span><span class="va">class</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/mclust.noise1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We now create a data set that does not satisfy the model:</p>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">31</span><span class="op">)</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, rate <span class="op">=</span> <span class="fl">.2</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span>
<span class="va">mu2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">20</span><span class="op">)</span>
<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">6</span>, max <span class="op">=</span> <span class="fl">6</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu2</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">mu3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">5</span>, <span class="op">-</span><span class="fl">5</span><span class="op">)</span>
<span class="va">x3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, sd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu3</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">x.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="va">x3</span><span class="op">)</span>

<span class="co"># run model-based clustering,</span>
<span class="co"># select the number of clusters using likelihood-base criterion</span>
<span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.3</span><span class="op">)</span>

<span class="co"># show the data, colors according to groups found</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.3</span>, col <span class="op">=</span> <span class="va">m3</span><span class="op">$</span><span class="va">class</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/wrong-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The problem is with the likelihood-based criterion used by
<code><a href="https://mclust-org.github.io/mclust/reference/mclust-package.html">mclust()</a></code> to select the number of clusters. Note that the
function increases until k = 3, and it
almost stops growing after k = 4. The
the maximum is nonetheless attained at k = 8.</p>
<div class="sourceCode" id="cb334"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">m3</span><span class="op">$</span><span class="va">BIC</span><span class="op">[</span>, <span class="fl">6</span><span class="op">]</span>, type <span class="op">=</span> <span class="st">"b"</span>, xlab <span class="op">=</span> <span class="st">"K"</span>, ylab <span class="op">=</span> <span class="st">"BIC"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/wrong.bic-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>It is interesting to note that
K-means would have found
the right number of clusters and cluster memberships
rather easily. Here is the sum-of-squares plot based
on K-means, which indicates that K = 3 is a sensible
choice:</p>
<div class="sourceCode" id="cb335"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># run k-means with k = 2, 2, ..., 10</span>
<span class="co"># to try to identify how many clusters are present</span>
<span class="va">m3.l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"list"</span>, <span class="fl">10</span><span class="op">)</span>
<span class="va">ss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">ss</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">m3.l</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">x.3</span>, centers <span class="op">=</span> <span class="va">i</span>, nstart <span class="op">=</span> <span class="fl">500</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">within</span><span class="op">)</span>
<span class="op">}</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">10</span>, <span class="va">ss</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>, xlab <span class="op">=</span> <span class="st">"K"</span>, ylab <span class="op">=</span> <span class="st">"W_k"</span>, type <span class="op">=</span> <span class="st">"b"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/wrong.kmeans.ss-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The clusters found when K-means was run with kK = 3 were:</p>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.3</span>, col <span class="op">=</span> <span class="va">m3.l</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">cluster</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/wrong.kmeans.clusters-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Furthermore, if you force <code><a href="https://mclust-org.github.io/mclust/reference/mclust-package.html">mclust()</a></code> to use 3 classes
it works fairly well, even thought the model is wrong. The
main problem here is that BIC depends heavily on the
assumed likelihood / probabilistic model:</p>
<div class="sourceCode" id="cb337"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m3.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.3</span>, G <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.3</span>, col <span class="op">=</span> <span class="va">m3.3</span><span class="op">$</span><span class="va">class</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/wrong.forced-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="behaviour-when-there-are-noise-variables" class="section level2">
<h2>
<span class="header-section-number">22.4</span> Behaviour when there are noise variables<a class="anchor" aria-label="anchor" href="#behaviour-when-there-are-noise-variables"><i class="fas fa-link"></i></a>
</h2>
<p>The presence of noise variables (i.e. features that
are non-informative about clusters that may
be present in the data) can be quite damaging to
these methods (both K-means and mclust)
We will create two data sets with “noise” features:
one with Gaussian noise, and
one with uniformly distributed noise.</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">31</span><span class="op">)</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, mean <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">s1.sqrt</span>
<span class="va">mu2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">9</span>, <span class="fl">9</span>, <span class="fl">3</span><span class="op">)</span>
<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">s2.sqrt</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu2</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">mu3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span>, <span class="op">-</span><span class="fl">10</span><span class="op">)</span>
<span class="va">x3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">3</span><span class="op">)</span>, center <span class="op">=</span> <span class="op">-</span><span class="va">mu3</span>, scale <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="va">x3</span><span class="op">)</span>
<span class="co"># non-normal "noise" features</span>
<span class="va">x.4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span> <span class="op">*</span> <span class="fl">3</span>, rate <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span>, <span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>
<span class="co"># normal "noise" features</span>
<span class="va">x.5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">3</span> <span class="op">*</span> <span class="fl">3</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">150</span><span class="op">)</span>, <span class="va">n</span> <span class="op">*</span> <span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We now find clusters using a Gaussian model,
and select the number of clusters using likelihood-base criterion:</p>
<div class="sourceCode" id="cb339"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.4</span><span class="op">)</span>
<span class="va">m5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.5</span><span class="op">)</span></code></pre></div>
<p>If we use the first 3
features (which are the ones that determine the
cluster structure)
to
show the clusters found by <code>mclust</code>
when the noise was not Gaussian, we get:</p>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.4</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, col <span class="op">=</span> <span class="va">m4</span><span class="op">$</span><span class="va">class</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/unif.noise.mclust-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>And even when the noise had a Gaussian
distribution, we do not identify the ``right’’ clusters:</p>
<div class="sourceCode" id="cb341"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># pairs(x.5[,1:3], col=m5$class, pch=19)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">m5</span><span class="op">$</span><span class="va">class</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt;       1   2   3</span>
<span class="co">#&gt;   1 300   1   0</span>
<span class="co">#&gt;   2   0 299   0</span>
<span class="co">#&gt;   3   0   0 300</span></code></pre></div>
<p>If we force <code><a href="https://mclust-org.github.io/mclust/reference/mclust-package.html">mclust()</a></code> to identify 3 clusters, things look
much better both for Gaussian and non-Gaussian noise:</p>
<div class="sourceCode" id="cb342"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m4.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.4</span>, G <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">m5.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mclust-org.github.io/mclust/reference/Mclust.html">Mclust</a></span><span class="op">(</span><span class="va">x.5</span>, G <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co"># it works well</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.4</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, col <span class="op">=</span> <span class="va">m4.3</span><span class="op">$</span><span class="va">class</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/force.noise.mclust-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb343"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.5</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, col <span class="op">=</span> <span class="va">m5.3</span><span class="op">$</span><span class="va">class</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/force.noise.mclust-2.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb344"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">m4.3</span><span class="op">$</span><span class="va">class</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt;       1   2   3</span>
<span class="co">#&gt;   1 300   5   0</span>
<span class="co">#&gt;   2   0 295   0</span>
<span class="co">#&gt;   3   0   0 300</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">m5.3</span><span class="op">$</span><span class="va">class</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt;       1   2   3</span>
<span class="co">#&gt;   1 300   1   0</span>
<span class="co">#&gt;   2   0 299   0</span>
<span class="co">#&gt;   3   0   0 300</span></code></pre></div>
<p>Note that noise also affects K-means seriously.
I refer you to the robust and sparse K-means
method (links on the module’s main page).</p>
<p>Within sum-of-squares plot
for K-means with non-Gaussian noise:</p>
<div class="sourceCode" id="cb345"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m4.l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"list"</span>, <span class="fl">10</span><span class="op">)</span>
<span class="va">ss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">ss</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">m4.l</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">x.4</span>, centers <span class="op">=</span> <span class="va">i</span>, nstart <span class="op">=</span> <span class="fl">100</span>, iter.max <span class="op">=</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">within</span><span class="op">)</span>
<span class="op">}</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">10</span>, <span class="va">ss</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>, xlab <span class="op">=</span> <span class="st">"K"</span>, ylab <span class="op">=</span> <span class="st">"W_k"</span>, type <span class="op">=</span> <span class="st">"b"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/unif.noise.kmeans-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Within sum-of-squares plot
for K-means with Gaussian noise:</p>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m5.l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"list"</span>, <span class="fl">10</span><span class="op">)</span>
<span class="va">ss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">ss</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">m5.l</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">x.5</span>, centers <span class="op">=</span> <span class="va">i</span>, nstart <span class="op">=</span> <span class="fl">100</span>, iter.max <span class="op">=</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">within</span><span class="op">)</span>
<span class="op">}</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">10</span>, <span class="va">ss</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>, xlab <span class="op">=</span> <span class="st">"K"</span>, ylab <span class="op">=</span> <span class="st">"W_k"</span>, type <span class="op">=</span> <span class="st">"b"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/gauss.noise.kmeans-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Not even forcing <code>k-means</code> to identify 3 clusters helps when
there are noise features:</p>
<div class="sourceCode" id="cb347"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.4</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, col <span class="op">=</span> <span class="va">m4.l</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">cluster</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/force.noise.kmeans-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">x.5</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>, col <span class="op">=</span> <span class="va">m5.l</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">cluster</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/force.noise.kmeans-2.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="imputation-via-em-a-detailed-example-by-hand" class="section level2">
<h2>
<span class="header-section-number">22.5</span> Imputation via EM (a detailed example “by hand”)<a class="anchor" aria-label="anchor" href="#imputation-via-em-a-detailed-example-by-hand"><i class="fas fa-link"></i></a>
</h2>
<p>Missing data is a rather prevalent problem,
and different strategies to replace them by sensible
“predictions” exit. They are collectively
called “imputation methods”. In these notes we will
follow the missing data example discussed in class and
use the EM algorithm to impute partially unobserved data points in a
synthetic bivariate Gaussian data set. Furthemore, the scripts
below are designed for the case where only one
entry may be missing in each observation. It is not
difficult to extend this to data with more coordinates
and more than one entry missing. Please refer to your
class notes for formulas and details.</p>
<div id="a-synthetic-example" class="section level3">
<h3>
<span class="header-section-number">22.5.1</span> A synthetic example<a class="anchor" aria-label="anchor" href="#a-synthetic-example"><i class="fas fa-link"></i></a>
</h3>
<p>To illustrate the method in a simple setting where
we can visualize the ideas on a 2-dimensional scatter
plot, we will work with a <em>toy</em> example.
We first create a simple synthetic data set with
50 observations in 2 dimensions, normally distributed with center
at the point (3,7), and a fairly strong correlation
between its two coordinates:</p>
<div class="sourceCode" id="cb349"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://mvtnorm.R-forge.R-project.org">mvtnorm</a></span><span class="op">)</span>
<span class="co"># mean vector</span>
<span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">7</span><span class="op">)</span>
<span class="co"># variance/covariance matrix</span>
<span class="va">si</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1.2</span>, <span class="fl">1.2</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>
<span class="co"># generate data</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/mvtnorm/man/Mvnorm.html">rmvnorm</a></span><span class="op">(</span><span class="fl">50</span>, mean <span class="op">=</span> <span class="va">mu</span>, sigma <span class="op">=</span> <span class="va">si</span><span class="op">)</span></code></pre></div>
<p>This is the data. The larger red point indicates
the sample mean (3.13, 7.15):</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/scatter0-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Assume we have an observation (5, <strong>NA</strong>) where the
second coordinate is missing, and
another one (<strong>NA</strong>, 5.5) with the first coordinate
missing. We indicate them with grey lines
to indicate the uncertainty about their missing
entries:</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/scatter.missing0-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>A simple method to impute the missing coordinates would be to
replace them by the mean of the missing variable over the
rest of the data. Hence (5, <strong>NA</strong>) becomes (5, <em>7.15</em>) and
(<strong>NA</strong>, 5.5) becomes (<em>3.13</em>, 5.5). The imputed points
are shown below as blue dots:</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/marginal0-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Note that the imputed points are in fact away from the bulk
of the data, even though this is not
apparent if you look at each
coordinate separately.
A better imputation method uses the EM algorithm.</p>
<p>We assume that the points in our data can be modelled as
occurences of a bivariate random vector with a normal / Gaussian
distribution. The unknown parameters are its mean vector
and 2x2 variance/covariance matrix. The EM algorithm will alternate
between computing the expected value of the log-likelihood for the
full (non-missing) data set conditional on the actually observed
points (even incompletely observed ones), and finding the
parameters (mean vector and covariance matrix) that maximize
this conditional expected log-likelihood.</p>
<p>It is not trivial to see that the conditional expected log-likelihood
equals a constant (that depends only on the parameters from the
previous iteration) plus the log-likelihood of a data set where the
missing coordinates of each observation are
replaced by their conditional expectation
(given the observed entries in the same unit). Refer to the
discussion in class for more details.</p>
<p>We now implement this imputation method in <code>R</code>. First add
the two incomplete observations to
the data set above, we append them at the “bottom” of the
matrix <code>x</code>:</p>
<div class="sourceCode" id="cb350"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="cn">NA</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fl">5.5</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Next, we compute initial values for the estimates of the parameters
of the model. These can be, for example, the sample mean and
sample covariance matrix using only the fully observed
data points:</p>
<div class="sourceCode" id="cb351"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">dat</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">si</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">dat</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<p>Before we start the EM iterations it will be helpful to
keep track of wich observations are missing a coordinate
(we store their indices in the vector <code>mi</code>):</p>
<div class="sourceCode" id="cb352"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
<span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">2</span>
<span class="co"># find observations with a missing coordinate</span>
<span class="va">mi</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">[</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span><span class="op">]</span></code></pre></div>
<p>Out of the n (52) rows in <code>x</code>, the ones with some
missing coordinates are: 51, 52.</p>
<p>Now we run 100 iterations of the EM algorithm, although convergence
is achieved much sooner:</p>
<div class="sourceCode" id="cb353"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># For this data we don't need many iterations</span>
<span class="va">niter</span> <span class="op">&lt;-</span> <span class="fl">100</span>
<span class="co"># how many observations with missing entries:</span>
<span class="va">len.mi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">mi</span><span class="op">)</span>
<span class="co"># Start the EM iterations</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">niter</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># E step</span>
  <span class="co"># impute the data points with missing entries</span>
  <span class="kw">for</span> <span class="op">(</span><span class="va">h</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">len.mi</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># which entries are not missing?</span>
    <span class="va">nm</span> <span class="op">&lt;-</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">dat</span><span class="op">[</span><span class="va">mi</span><span class="op">[</span><span class="va">h</span><span class="op">]</span>, <span class="op">]</span><span class="op">)</span>
    <span class="va">dat</span><span class="op">[</span><span class="va">mi</span><span class="op">[</span><span class="va">h</span><span class="op">]</span>, <span class="op">!</span><span class="va">nm</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">mu</span><span class="op">[</span><span class="op">!</span><span class="va">nm</span><span class="op">]</span> <span class="op">+</span> <span class="va">si</span><span class="op">[</span><span class="op">!</span><span class="va">nm</span>, <span class="va">nm</span><span class="op">]</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="va">si</span><span class="op">[</span><span class="va">nm</span>, <span class="va">nm</span><span class="op">]</span>, <span class="va">dat</span><span class="op">[</span><span class="va">mi</span><span class="op">[</span><span class="va">h</span><span class="op">]</span>, <span class="va">nm</span><span class="op">]</span> <span class="op">-</span> <span class="va">mu</span><span class="op">[</span><span class="va">nm</span><span class="op">]</span><span class="op">)</span>
  <span class="op">}</span>
  <span class="co"># M step, luckily we have a closed form for the maximizers of the</span>
  <span class="co"># conditional expected likelihood</span>
  <span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
  <span class="va">si</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>The imputed data are now much more in line with the
shape and distribution of the other points in the data set:</p>
<div class="inline-figure"><img src="53-model-based-clustering_files/figure-html/em-imputed-1.png" width="90%" style="display: block; margin: auto;"></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="clustering.html"><span class="header-section-number">21</span> Clustering</a></div>
<div class="next"><a href="hierarchical-clustering.html"><span class="header-section-number">23</span> Hierarchical clustering</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-based-clustering"><span class="header-section-number">22</span> Model based clustering</a></li>
<li><a class="nav-link" href="#em-algorithm"><span class="header-section-number">22.1</span> EM algorithm</a></li>
<li><a class="nav-link" href="#bivariate-gaussian-mixture-model-via-em-by-hand"><span class="header-section-number">22.2</span> Bivariate Gaussian mixture model via EM “by hand”</a></li>
<li><a class="nav-link" href="#model-assumptions-may-be-important"><span class="header-section-number">22.3</span> Model assumptions may be important</a></li>
<li><a class="nav-link" href="#behaviour-when-there-are-noise-variables"><span class="header-section-number">22.4</span> Behaviour when there are noise variables</a></li>
<li>
<a class="nav-link" href="#imputation-via-em-a-detailed-example-by-hand"><span class="header-section-number">22.5</span> Imputation via EM (a detailed example “by hand”)</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#a-synthetic-example"><span class="header-section-number">22.5.1</span> A synthetic example</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/ubc-stat/stat-406-worksheets/blob/main/53-model-based-clustering.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/ubc-stat/stat-406-worksheets/edit/main/53-model-based-clustering.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>UBC Stat 406 Worksheets</strong>" was written by Daniel J. McDonald and Matías Salibán-Barrera. It was last built on 2021-09-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
