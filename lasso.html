<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 LASSO | UBC Stat 406 Worksheets</title>
<meta name="author" content="Daniel J. McDonald and Matías Salibán-Barrera">
<meta name="description" content="A different approach to perform some kind of variable selection that may be more stable than stepwise methods is to use an L1 regularization term (instead of the L2 one used in ridge regression)....">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="6 LASSO | UBC Stat 406 Worksheets">
<meta property="og:type" content="book">
<meta property="og:url" content="https://ubc-stat.github.io/stat-406-worksheets/lasso.html">
<meta property="og:description" content="A different approach to perform some kind of variable selection that may be more stable than stepwise methods is to use an L1 regularization term (instead of the L2 one used in ridge regression)....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 LASSO | UBC Stat 406 Worksheets">
<meta name="twitter:description" content="A different approach to perform some kind of variable selection that may be more stable than stepwise methods is to use an L1 regularization term (instead of the L2 one used in ridge regression)....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">UBC Stat 406 Worksheets</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Stat 406 Worksheets</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Module 0 – Review</li>
<li><a class="" href="predictions-using-a-linear-model.html"><span class="header-section-number">1</span> Predictions using a linear model</a></li>
<li class="book-part">Module 1 – Model Selection</li>
<li><a class="" href="predictions-using-a-linear-model-continued.html"><span class="header-section-number">2</span> Predictions using a linear model (continued)</a></li>
<li><a class="" href="cross-validation-concerns.html"><span class="header-section-number">3</span> Cross-validation concerns</a></li>
<li><a class="" href="comparing-models.html"><span class="header-section-number">4</span> Comparing models</a></li>
<li class="book-part">Module 2 – Regression</li>
<li><a class="" href="ridge-regression.html"><span class="header-section-number">5</span> Ridge regression</a></li>
<li><a class="active" href="lasso.html"><span class="header-section-number">6</span> LASSO</a></li>
<li><a class="" href="non-parametric-regression.html"><span class="header-section-number">7</span> Non-parametric regression</a></li>
<li><a class="" href="kernel-regression-local-regression.html"><span class="header-section-number">8</span> Kernel regression / local regression</a></li>
<li><a class="" href="regression-trees.html"><span class="header-section-number">9</span> Regression trees</a></li>
<li><a class="" href="pruning-regression-trees-with-rpart.html"><span class="header-section-number">10</span> Pruning regression trees with rpart</a></li>
<li class="book-part">Module 3 – Classification</li>
<li><a class="" href="parametric-classifiers.html"><span class="header-section-number">11</span> Parametric classifiers</a></li>
<li><a class="" href="qda.html"><span class="header-section-number">12</span> QDA</a></li>
<li><a class="" href="classification-trees.html"><span class="header-section-number">13</span> Classification Trees</a></li>
<li><a class="" href="bagging-for-regression.html"><span class="header-section-number">14</span> Bagging for regression</a></li>
<li><a class="" href="bagging-for-classification.html"><span class="header-section-number">15</span> Bagging for classification</a></li>
<li><a class="" href="random-forests.html"><span class="header-section-number">16</span> Random Forests</a></li>
<li><a class="" href="boosting-a-statistical-learning-perspective.html"><span class="header-section-number">17</span> Boosting (a Statistical Learning perspective)</a></li>
<li><a class="" href="what-is-adaboost-doing-really.html"><span class="header-section-number">18</span> What is Adaboost doing, really?</a></li>
<li><a class="" href="single-layer-neural-network.html"><span class="header-section-number">19</span> Single layer neural network</a></li>
<li class="book-part">Module 5 – Unsupervised learning</li>
<li><a class="" href="introduction.html"><span class="header-section-number">20</span> Introduction</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">21</span> Clustering</a></li>
<li><a class="" href="model-based-clustering.html"><span class="header-section-number">22</span> Model based clustering</a></li>
<li><a class="" href="hierarchical-clustering.html"><span class="header-section-number">23</span> Hierarchical clustering</a></li>
<li><a class="" href="references.html">References</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="alt-pca.html"><span class="header-section-number">A</span> PCA and alternating regression</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/ubc-stat/stat-406-worksheets">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="lasso" class="section level1">
<h1>
<span class="header-section-number">6</span> LASSO<a class="anchor" aria-label="anchor" href="#lasso"><i class="fas fa-link"></i></a>
</h1>
<p>A different approach to perform <em>some kind</em> of variable selection that may be
more stable than stepwise methods is to use an L1 regularization term
(instead of the L2 one used in ridge regression). Notwidthstanding the
geometric “interpretation” of the effect of using an L1 penalty,
it can also be argued that the L1 norm is, in some cases, a convex relaxation
(envelope) of the “L0” norm (the number of non-zero elements). As a result,
estimators based on the LASSO (L1-regularized regression) will typically have some
of their entries equal to zero.</p>
<p>Just as it was the case for Ridge Regression,
as the value of the penalty parameter increases, the solutions
to the L1 regularized problem change
from the usual least squares estimator (when the regularization parameter equals
to zero) to a vector of all zeroes (when the penalty constant is sufficiently
large). One difference between using an L1 or an L2 penalty is that
for an L1-regularized problem, there usually is a finite value of the penalty term
that produces a solution of all zeroes, whereas for the L2 penalizations
this is not generally true.</p>
<p>The sequence of solutions changing by value of the penalty parameter
is often used as a way to rank (or “sequence”) the explanatory variables, listing them
in the order in which they “enter” (their estimated coefficient changes from
zero to a non-zero value). We can
also estimate the MSPE of each solution (on a finite
grid of values of the penalty parameter) to select one with
good prediction properties. If any of the
estimated regression coefficients in the selected solution are exactly zero it
is commonly said that those explanatory variables are not included
in the chosen model.</p>
<p>There are two main implementation of the LASSO in <code>R</code>, one is
via the <code>glmnet</code> function (in package <code>glmnet</code>), and the other
is with the function <code>lars</code> in package <code>lars</code>. Both, of course,
compute the same estimators, but they do so in different ways.</p>
<p>We first compute the path of LASSO solutions for the <code>credit</code> data
used in previous lectures:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/Credit.csv"</span>, sep <span class="op">=</span> <span class="st">","</span>, header <span class="op">=</span> <span class="cn">TRUE</span>, row.names <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co"># use non-factor variables</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, <span class="fl">11</span><span class="op">)</span><span class="op">]</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Balance</span><span class="op">)</span>
<span class="va">xm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="op">-</span><span class="fl">7</span><span class="op">]</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span>
<span class="co"># alpha = 1 - LASSO</span>
<span class="va">lambdas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">10</span>, length <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span>
<span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="va">lambdas</span><span class="op">)</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, alpha <span class="op">=</span> <span class="fl">1</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span></code></pre></div>
<p>The <code>plot</code> method can be used to show the path of solutions, just as
we did for ridge regression:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">a</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>, lwd <span class="op">=</span> <span class="fl">6</span>, cex.axis <span class="op">=</span> <span class="fl">1.5</span>, cex.lab <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditlasso3-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Using <code><a href="https://rdrr.io/pkg/lars/man/lars.html">lars::lars()</a></code> we obtain:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www-stat.stanford.edu/~hastie/Papers/#LARS">lars</a></span><span class="op">)</span>
<span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lars/man/lars.html">lars</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, type <span class="op">=</span> <span class="st">"lasso"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">b</span>, lwd <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditlars1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>With <code>lars</code> the returned object is a matrix of regression estimators, one
for each value of the penalty constant where a new coefficient “enters” the
model:</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># see the variables</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">b</span><span class="op">)</span>
<span class="co">#&gt;         Income      Limit   Rating     Cards        Age Education</span>
<span class="co">#&gt; [1,]  0.000000 0.00000000 0.000000  0.000000  0.0000000  0.000000</span>
<span class="co">#&gt; [2,]  0.000000 0.00000000 1.835963  0.000000  0.0000000  0.000000</span>
<span class="co">#&gt; [3,]  0.000000 0.01226464 2.018929  0.000000  0.0000000  0.000000</span>
<span class="co">#&gt; [4,] -4.703898 0.05638653 2.433088  0.000000  0.0000000  0.000000</span>
<span class="co">#&gt; [5,] -5.802948 0.06600083 2.545810  0.000000 -0.3234748  0.000000</span>
<span class="co">#&gt; [6,] -6.772905 0.10049065 2.257218  6.369873 -0.6349138  0.000000</span>
<span class="co">#&gt; [7,] -7.558037 0.12585115 2.063101 11.591558 -0.8923978  1.998283</span>
<span class="va">b</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lars(x = xm, y = y, type = "lasso", intercept = TRUE)</span>
<span class="co">#&gt; R-squared: 0.878 </span>
<span class="co">#&gt; Sequence of LASSO moves:</span>
<span class="co">#&gt;      Rating Limit Income Age Cards Education</span>
<span class="co">#&gt; Var       3     2      1   5     4         6</span>
<span class="co">#&gt; Step      1     2      3   4     5         6</span></code></pre></div>
<p>The presentation below exploits the fact that the LASSO regression estimators
are piecewise linear between values of the regularization parameter where
a variable enters or drops the model.</p>
<p>In order to select one LASSO estimator (among the infinitely many that
are possible) we can use K-fold CV to estimate the MSPE of a few of them
(for a grid of values of the penalty parameter, for example), and
choose the one with smallest estimated MSPE:</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># select one solution</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">tmp.la</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lars/man/cv.lars.html">cv.lars</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>, type <span class="op">=</span> <span class="st">"lasso"</span>, K <span class="op">=</span> <span class="fl">5</span>,
  index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditlars3-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Given their random nature, it is always a good idea to run K-fold CV experiments
more than once:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">tmp.la</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lars/man/cv.lars.html">cv.lars</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>, type <span class="op">=</span> <span class="st">"lasso"</span>, K <span class="op">=</span> <span class="fl">5</span>,
  index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditlars4-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We now repeat the same steps as above but using the implementation
in <code>glmnet</code>:</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># run 5-fold CV with glmnet()</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">1</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">tmp</span>, lwd <span class="op">=</span> <span class="fl">6</span>, cex.axis <span class="op">=</span> <span class="fl">1.5</span>, cex.lab <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditcv-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We ran CV again:</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">1</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">tmp</span>, lwd <span class="op">=</span> <span class="fl">6</span>, cex.axis <span class="op">=</span> <span class="fl">1.5</span>, cex.lab <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditcv2-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Zoom in the CV plot to check the 1-SE rule:</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">tmp</span>, lwd <span class="op">=</span> <span class="fl">6</span>, cex.axis <span class="op">=</span> <span class="fl">1.5</span>, cex.lab <span class="op">=</span> <span class="fl">1.2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">22000</span>, <span class="fl">33000</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/creditcv4-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The returned object includes the “optimal” value of the
penalization parameter, which can be used to
find the corresponding estimates for the regression
coefficients, using the method <code>coef</code>:</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># optimal lambda</span>
<span class="va">tmp</span><span class="op">$</span><span class="va">lambda.min</span>
<span class="co">#&gt; [1] 0.04978707</span>
<span class="co"># coefficients for the optimal lambda</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">tmp</span>, s <span class="op">=</span> <span class="va">tmp</span><span class="op">$</span><span class="va">lambda.min</span><span class="op">)</span>
<span class="co">#&gt; 7 x 1 sparse Matrix of class "dgCMatrix"</span>
<span class="co">#&gt;                       s1</span>
<span class="co">#&gt; (Intercept) -481.9460966</span>
<span class="co">#&gt; Income        -7.5489897</span>
<span class="co">#&gt; Limit          0.1141714</span>
<span class="co">#&gt; Rating         2.2352534</span>
<span class="co">#&gt; Cards         10.7283522</span>
<span class="co">#&gt; Age           -0.8914429</span>
<span class="co">#&gt; Education      2.0194979</span></code></pre></div>
<p>We can also use <code>coef</code> to compute the coefficients at
any value of the penalty parameter. For example we
show below the coefficients corresponding
to penalty values of exp(4) and exp(4.5):</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># coefficients for other values of lambda</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">tmp</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; 7 x 1 sparse Matrix of class "dgCMatrix"</span>
<span class="co">#&gt;                        s1</span>
<span class="co">#&gt; (Intercept) -262.35053476</span>
<span class="co">#&gt; Income        -0.63094341</span>
<span class="co">#&gt; Limit          0.02749778</span>
<span class="co">#&gt; Rating         1.91772580</span>
<span class="co">#&gt; Cards          .         </span>
<span class="co">#&gt; Age            .         </span>
<span class="co">#&gt; Education      .</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">tmp</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">4.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># note no. of zeroes...</span>
<span class="co">#&gt; 7 x 1 sparse Matrix of class "dgCMatrix"</span>
<span class="co">#&gt;                        s1</span>
<span class="co">#&gt; (Intercept) -175.98151842</span>
<span class="co">#&gt; Income         .         </span>
<span class="co">#&gt; Limit          0.01492881</span>
<span class="co">#&gt; Rating         1.76170516</span>
<span class="co">#&gt; Cards          .         </span>
<span class="co">#&gt; Age            .         </span>
<span class="co">#&gt; Education      .</span></code></pre></div>
<div id="compare-mspes-of-ridge-lasso-on-the-credit-data" class="section level2">
<h2>
<span class="header-section-number">6.1</span> Compare MSPEs of Ridge &amp; LASSO on the credit data<a class="anchor" aria-label="anchor" href="#compare-mspes-of-ridge-lasso-on-the-credit-data"><i class="fas fa-link"></i></a>
</h2>
<p>We now use 50 runs of 5-fold cross-validation to
estimate (and compare) the MSPEs of the different
estimators / predictors:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">xm</span><span class="op">)</span>
<span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">5</span>
<span class="va">ii</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">)</span><span class="op">%%</span><span class="va">k</span> <span class="op">+</span> <span class="fl">1</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>
<span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">50</span>
<span class="va">mspe.la</span> <span class="op">&lt;-</span> <span class="va">mspe.st</span> <span class="op">&lt;-</span> <span class="va">mspe.ri</span> <span class="op">&lt;-</span> <span class="va">mspe.f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">N</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">N</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">ii</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">ii</span><span class="op">)</span>
    <span class="va">pr.la</span> <span class="op">&lt;-</span> <span class="va">pr.f</span> <span class="op">&lt;-</span> <span class="va">pr.ri</span> <span class="op">&lt;-</span> <span class="va">pr.st</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span><span class="op">)</span>
    <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span>
        <span class="va">tmp.ri</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">xm</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span><span class="op">]</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>,
            nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0</span>, family <span class="op">=</span> <span class="st">"gaussian"</span><span class="op">)</span>
        <span class="va">tmp.la</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">xm</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span><span class="op">]</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>,
            nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"gaussian"</span><span class="op">)</span>
        <span class="va">null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Balance</span> <span class="op">~</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
        <span class="va">full</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Balance</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">!=</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
        <span class="va">tmp.st</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/stepAIC.html">stepAIC</a></span><span class="op">(</span><span class="va">null</span>, scope <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="va">null</span>, upper <span class="op">=</span> <span class="va">full</span><span class="op">)</span>, trace <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
        <span class="va">pr.ri</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tmp.ri</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newx <span class="op">=</span> <span class="va">xm</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
        <span class="va">pr.la</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tmp.la</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newx <span class="op">=</span> <span class="va">xm</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
        <span class="va">pr.st</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tmp.st</span>, newdata <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
        <span class="va">pr.f</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">full</span>, newdata <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">ii</span> <span class="op">==</span> <span class="va">j</span>, <span class="op">]</span><span class="op">)</span>
    <span class="op">}</span>
    <span class="va">mspe.ri</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Balance</span> <span class="op">-</span> <span class="va">pr.ri</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
    <span class="va">mspe.la</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Balance</span> <span class="op">-</span> <span class="va">pr.la</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
    <span class="va">mspe.st</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Balance</span> <span class="op">-</span> <span class="va">pr.st</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
    <span class="va">mspe.f</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Balance</span> <span class="op">-</span> <span class="va">pr.f</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="op">}</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span><span class="op">(</span><span class="va">mspe.la</span>, <span class="va">mspe.ri</span>, <span class="va">mspe.st</span>, <span class="va">mspe.f</span>, names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"LASSO"</span>, <span class="st">"Ridge"</span>, <span class="st">"Stepwise"</span>,
    <span class="st">"Full"</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"steelblue"</span>, <span class="st">"gray80"</span>, <span class="st">"tomato"</span>, <span class="st">"springgreen"</span><span class="op">)</span>, cex.axis <span class="op">=</span> <span class="fl">1</span>,
    cex.lab <span class="op">=</span> <span class="fl">1</span>, cex.main <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/plotmath.html">hat</a></span><span class="op">(</span><span class="va">MSPE</span><span class="op">)</span><span class="op">)</span>, side <span class="op">=</span> <span class="fl">2</span>, line <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/mspecredit-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We see that in this example LASSO does not seem to provide better
predictions than Ridge Regression. However, it does yield a
sequence of explanatory variables that can be interpreted as
based on “importance” for the linear regression model (see
above).</p>
</div>
<div id="comparing-lasso-with-ridge-regression-on-the-air-pollution-data" class="section level2">
<h2>
<span class="header-section-number">6.2</span> Comparing LASSO with Ridge Regression on the air pollution data<a class="anchor" aria-label="anchor" href="#comparing-lasso-with-ridge-regression-on-the-air-pollution-data"><i class="fas fa-link"></i></a>
</h2>
<p>Let us compare the Ridge Regression and LASSO fits to the
air pollution data. Of course, by <em>the Ridge Regression fit</em>
and <em>the LASSO fit</em> we mean the fit obtained with the
optimal value of the penalty constant chosen in terms
of the corresponding estimated MSPE (which is in
general estimated using K-fold cross validation).</p>
<p>We first load the data and use <code><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet()</a></code> with
<code>alpha = 0</code> to select an <strong>approximately optimal</strong>
Ridge Regression fit (what makes the calculation
below <strong>only approximately</strong> optimal?).</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">airp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"data/rutgers-lib-30861_CSV-1.csv"</span>, header <span class="op">=</span> <span class="cn">TRUE</span>, sep <span class="op">=</span> <span class="st">","</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span><span class="op">(</span><span class="va">airp</span><span class="op">$</span><span class="va">MORT</span><span class="op">)</span>
<span class="va">xm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">airp</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">airp</span><span class="op">)</span> <span class="op">!=</span> <span class="st">"MORT"</span><span class="op">]</span><span class="op">)</span>
<span class="va">lambdas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">10</span>, length <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span>
<span class="co"># Ridge Regression</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.l2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">air.l2</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/comparing.airp-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The plot above is included for illustration purposes only.
Similarly, we now compute an approximately optimal LASSO fit,
and look at the curve of estimated MSPEs:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># LASSO</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">1</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">air.l1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/airp.lasso-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>It is interesting to compare the corresponding estimated regression coefficients,
so we put them side by side in two columns:</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.l2</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.l1</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>
<span class="op">)</span>
<span class="co">#&gt; 16 x 2 sparse Matrix of class "dgCMatrix"</span>
<span class="co">#&gt;                   s1       s1</span>
<span class="co">#&gt; (Intercept) 1129.267 1070.341</span>
<span class="co">#&gt; PREC           1.493    1.420</span>
<span class="co">#&gt; JANT          -0.999   -1.124</span>
<span class="co">#&gt; JULT          -1.054   -0.877</span>
<span class="co">#&gt; OVR65         -2.260    .    </span>
<span class="co">#&gt; POPN          -1.621    .    </span>
<span class="co">#&gt; EDUC          -8.280  -10.800</span>
<span class="co">#&gt; HOUS          -1.164   -0.380</span>
<span class="co">#&gt; DENS           0.005    0.003</span>
<span class="co">#&gt; NONW           2.895    3.825</span>
<span class="co">#&gt; WWDRK         -0.464    .    </span>
<span class="co">#&gt; POOR           0.653    .    </span>
<span class="co">#&gt; HC            -0.030    .    </span>
<span class="co">#&gt; NOX            0.056    .    </span>
<span class="co">#&gt; SO.            0.237    0.226</span>
<span class="co">#&gt; HUMID          0.388    .</span></code></pre></div>
<p>Note how several of them are relatively similar, but LASSO includes fewer of them.
A possible explanation for this is the particular correlation structure among the
explanatory variables. More specifically, when groups of
correlated covariates are present,
LASSO tends to choose only one of them, whereas Ridge Regression will tend
to keep all of them. For a formal statement see <span class="citation">(Zou and Hastie <a href="references.html#ref-ZouHastie2005" role="doc-biblioref">2005</a>, Lemma 2)</span>.</p>
<p>It is important to note here that the above observations regarding the Ridge Regression
and LASSO fits trained on the air pollution data should be made on a more
reliable (more stable, less variable) choice of penalty parameter. For example,
we may want to run the above 5-fold CV experiments several times and take the
average of the estimated optimal penalty parameters. To simplify the presentation
we do not purse this here, but it may be a very good exercise for the reader to
do so.</p>
<p>The following heatmap of the pairwise correlations among explanatory variables
reveals certain patterns that may be used to explain the difference
mentioned above. Note that in this visualization method variables were
grouped (“clustered”) according to their pairwise correlations in order to
improve the interpretability of the plot. We will see later in this course
the particular clustering method used here (hierarchical clustering).</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/wiki/ggcorrplot">ggcorrplot</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/ggcorrplot/man/ggcorrplot.html">ggcorrplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">xm</span><span class="op">)</span>, hc.order <span class="op">=</span> <span class="cn">TRUE</span>, outline.col <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/airp.correlations-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="compare-mspe-of-ridge-and-lasso-on-air-pollution-data" class="section level2">
<h2>
<span class="header-section-number">6.3</span> Compare MSPE of Ridge and LASSO on air pollution data<a class="anchor" aria-label="anchor" href="#compare-mspe-of-ridge-and-lasso-on-air-pollution-data"><i class="fas fa-link"></i></a>
</h2>
<p>Since our focus was on the properties of the resulting predictions, it may be
interesting to compare the estimated MSPE of the different models / predictors
we have considered so far: a full linear model, a model selected via stepwise + AIC,
ridge regression and LASSO. As usual, we use 50 runs of 5-fold CV, and obtain
the following boxplots:</p>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/bigcompare-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We see that there is a marginal advantage of LASSO, but it is rather minor, and
the three methods we have seen so far improve by similar margins
on the predictions obtained by using a full linear regression model.</p>
</div>
<div id="less-desirable-properties-of-lasso" class="section level2">
<h2>
<span class="header-section-number">6.4</span> Less desirable properties of LASSO<a class="anchor" aria-label="anchor" href="#less-desirable-properties-of-lasso"><i class="fas fa-link"></i></a>
</h2>
<p>As important as the LASSO estimator has been, its properties may sometimes
not be fully satisfactory. In particular:</p>
<ul>
<li>The LASSO selects the right variables only under very restrictive conditions (in other words, it is generally not “variable selection”-consistent).</li>
<li>The LASSO sampling distribution is not the same as the one we would obtain with the standard least squares estimator if we knew which features to include and which ones to exclude from the model (in orther words, the LASSO does not have an “oracle” property).</li>
<li>When groups of correlated explanatory variables are present the LASSO tends to include only one variable (randomly) from the group, relegate the others to the end of the sequence.</li>
</ul>
<p>For precise statements and theoretical results regarding the three points above, see <span class="citation">(Zou and Hastie <a href="references.html#ref-ZouHastie2005" role="doc-biblioref">2005</a>; Zou <a href="references.html#ref-Zou2006" role="doc-biblioref">2006</a>)</span>.</p>
</div>
<div id="elastic-net" class="section level2">
<h2>
<span class="header-section-number">6.5</span> Elastic net<a class="anchor" aria-label="anchor" href="#elastic-net"><i class="fas fa-link"></i></a>
</h2>
<p>Elastic Net estimators were introduced to find an
informative compromise between LASSO and Ridge Regression.</p>
<p>Note that <code>cv.glmnet</code> only considers fits with variying
values of one of the penalty constants, while the other
one (<code>alpha</code>) is kept fixed. To compare different
Elastic Net fits we run <code>cv.glmnet</code> with 4 values of
<code>alpha</code>: 0.05, 0.1, 0.5 and 0.75.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># EN</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.en.75</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0.75</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.en.05</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0.05</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.en.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0.1</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>
<span class="va">air.en.5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="va">xm</span>, y <span class="op">=</span> <span class="va">y</span>, lambda <span class="op">=</span> <span class="va">lambdas</span>, nfolds <span class="op">=</span> <span class="fl">5</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,
  family <span class="op">=</span> <span class="st">"gaussian"</span>, intercept <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">air.en.05</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/airp.en-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">air.en.5</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/airp.en-2.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">air.en.75</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/airp.en-3.png" width="90%" style="display: block; margin: auto;"></div>
<div id="run-en-on-airpollution-data-compare-fits" class="section level3">
<h3>
<span class="header-section-number">6.5.1</span> Run EN on airpollution data, compare fits<a class="anchor" aria-label="anchor" href="#run-en-on-airpollution-data-compare-fits"><i class="fas fa-link"></i></a>
</h3>
<p>We now compare the estimates of the regression coefficients
obtained with the different methods discussed so far to
alleviate potential problems caused by correlated covariates.</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.l2</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.l1</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.en.05</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.en.1</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.en.5</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">air.en.75</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">a</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Ridge"</span>, <span class="st">"LASSO"</span>, <span class="st">"EN-05"</span>, <span class="st">"EN-10"</span>, <span class="st">"EN-50"</span>, <span class="st">"EN-75"</span><span class="op">)</span>
<span class="va">a</span>
<span class="co">#&gt; 16 x 6 sparse Matrix of class "dgCMatrix"</span>
<span class="co">#&gt;                Ridge    LASSO    EN-05    EN-10    EN-50    EN-75</span>
<span class="co">#&gt; (Intercept) 1129.267 1070.341 1116.791 1112.228 1101.074 1099.067</span>
<span class="co">#&gt; PREC           1.493    1.420    1.479    1.481    1.498    1.495</span>
<span class="co">#&gt; JANT          -0.999   -1.124   -0.968   -0.990   -1.124   -1.153</span>
<span class="co">#&gt; JULT          -1.054   -0.877   -1.036   -1.041   -1.156   -1.182</span>
<span class="co">#&gt; OVR65         -2.260    .       -1.099   -0.265    .        .    </span>
<span class="co">#&gt; POPN          -1.621    .        .        .        .        .    </span>
<span class="co">#&gt; EDUC          -8.280  -10.800   -8.277   -8.413   -9.585  -10.147</span>
<span class="co">#&gt; HOUS          -1.164   -0.380   -1.136   -1.102   -0.705   -0.575</span>
<span class="co">#&gt; DENS           0.005    0.003    0.005    0.005    0.004    0.004</span>
<span class="co">#&gt; NONW           2.895    3.825    3.187    3.454    3.816    3.895</span>
<span class="co">#&gt; WWDRK         -0.464    .       -0.422   -0.391   -0.141   -0.052</span>
<span class="co">#&gt; POOR           0.653    .        0.268    .        .        .    </span>
<span class="co">#&gt; HC            -0.030    .       -0.006   -0.003    .        .    </span>
<span class="co">#&gt; NOX            0.056    .        0.000    .        .        .    </span>
<span class="co">#&gt; SO.            0.237    0.226    0.242    0.241    0.233    0.230</span>
<span class="co">#&gt; HUMID          0.388    .        0.290    0.241    0.061    0.005</span></code></pre></div>
<p>The same comment made above regarding the need of a
more stable choice of “optimal” fits (for each of these
methods) applies here. Again, here we limit ourselves to one
run of 5-fold CV purely based on simplifying the
presentation.</p>
</div>
<div id="compare-mspes-of-full-lasso-ridge-en-and-stepwise" class="section level3">
<h3>
<span class="header-section-number">6.5.2</span> Compare MSPE’s of Full, LASSO, Ridge, EN and stepwise<a class="anchor" aria-label="anchor" href="#compare-mspes-of-full-lasso-ridge-en-and-stepwise"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-figure"><img src="21-lasso-elnet_files/figure-html/bigcompare2-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We see that in this example Elastic Net with <code>alpha = 0.75</code> (which is not far from
the LASSO) provides slightly better estimated MSPEs.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="ridge-regression.html"><span class="header-section-number">5</span> Ridge regression</a></div>
<div class="next"><a href="non-parametric-regression.html"><span class="header-section-number">7</span> Non-parametric regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#lasso"><span class="header-section-number">6</span> LASSO</a></li>
<li><a class="nav-link" href="#compare-mspes-of-ridge-lasso-on-the-credit-data"><span class="header-section-number">6.1</span> Compare MSPEs of Ridge &amp; LASSO on the credit data</a></li>
<li><a class="nav-link" href="#comparing-lasso-with-ridge-regression-on-the-air-pollution-data"><span class="header-section-number">6.2</span> Comparing LASSO with Ridge Regression on the air pollution data</a></li>
<li><a class="nav-link" href="#compare-mspe-of-ridge-and-lasso-on-air-pollution-data"><span class="header-section-number">6.3</span> Compare MSPE of Ridge and LASSO on air pollution data</a></li>
<li><a class="nav-link" href="#less-desirable-properties-of-lasso"><span class="header-section-number">6.4</span> Less desirable properties of LASSO</a></li>
<li>
<a class="nav-link" href="#elastic-net"><span class="header-section-number">6.5</span> Elastic net</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#run-en-on-airpollution-data-compare-fits"><span class="header-section-number">6.5.1</span> Run EN on airpollution data, compare fits</a></li>
<li><a class="nav-link" href="#compare-mspes-of-full-lasso-ridge-en-and-stepwise"><span class="header-section-number">6.5.2</span> Compare MSPE’s of Full, LASSO, Ridge, EN and stepwise</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/ubc-stat/stat-406-worksheets/blob/main/21-lasso-elnet.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/ubc-stat/stat-406-worksheets/edit/main/21-lasso-elnet.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>UBC Stat 406 Worksheets</strong>" was written by Daniel J. McDonald and Matías Salibán-Barrera. It was last built on 2021-08-18.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
