<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>12 QDA | UBC Stat 406 Worksheets</title>
<meta name="author" content="Daniel J. McDonald and Matías Salibán-Barrera">
<meta name="description" content="Similarly to the way we derived the LDA classifier in class, if one relaxes the assumption that the conditional distribution of the vector of features X in each class has the same covariance...">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="12 QDA | UBC Stat 406 Worksheets">
<meta property="og:type" content="book">
<meta property="og:description" content="Similarly to the way we derived the LDA classifier in class, if one relaxes the assumption that the conditional distribution of the vector of features X in each class has the same covariance...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="12 QDA | UBC Stat 406 Worksheets">
<meta name="twitter:description" content="Similarly to the way we derived the LDA classifier in class, if one relaxes the assumption that the conditional distribution of the vector of features X in each class has the same covariance...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">UBC Stat 406 Worksheets</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li class="book-part">Module 0 – Review</li>
<li><a class="" href="predictions-using-a-linear-model.html"><span class="header-section-number">1</span> Predictions using a linear model</a></li>
<li class="book-part">Module 1 – Model Selection</li>
<li><a class="" href="predictions-using-a-linear-model-continued.html"><span class="header-section-number">2</span> Predictions using a linear model (continued)</a></li>
<li><a class="" href="cross-validation-concerns.html"><span class="header-section-number">3</span> Cross-validation concerns</a></li>
<li><a class="" href="comparing-models.html"><span class="header-section-number">4</span> Comparing models</a></li>
<li class="book-part">Module 2 – Regression</li>
<li><a class="" href="ridge-regression.html"><span class="header-section-number">5</span> Ridge regression</a></li>
<li><a class="" href="lasso.html"><span class="header-section-number">6</span> LASSO</a></li>
<li><a class="" href="non-parametric-regression.html"><span class="header-section-number">7</span> Non-parametric regression</a></li>
<li><a class="" href="kernel-regression-local-regression.html"><span class="header-section-number">8</span> Kernel regression / local regression</a></li>
<li><a class="" href="regression-trees.html"><span class="header-section-number">9</span> Regression trees</a></li>
<li><a class="" href="pruning-regression-trees-with-rpart.html"><span class="header-section-number">10</span> Pruning regression trees with rpart</a></li>
<li class="book-part">Module 3 – Classification</li>
<li><a class="" href="parametric-classifiers.html"><span class="header-section-number">11</span> Parametric classifiers</a></li>
<li><a class="active" href="qda.html"><span class="header-section-number">12</span> QDA</a></li>
<li><a class="" href="classification-trees.html"><span class="header-section-number">13</span> Classification Trees</a></li>
<li><a class="" href="bagging-for-regression.html"><span class="header-section-number">14</span> Bagging for regression</a></li>
<li><a class="" href="bagging-for-classification.html"><span class="header-section-number">15</span> Bagging for classification</a></li>
<li><a class="" href="random-forests.html"><span class="header-section-number">16</span> Random Forests</a></li>
<li><a class="" href="boosting-a-statistical-learning-perspective.html"><span class="header-section-number">17</span> Boosting (a Statistical Learning perspective)</a></li>
<li><a class="" href="what-is-adaboost-doing-really.html"><span class="header-section-number">18</span> What is Adaboost doing, really?</a></li>
<li><a class="" href="single-layer-neural-network.html"><span class="header-section-number">19</span> Single layer neural network</a></li>
<li class="book-part">Module 5 – Unsupervised learning</li>
<li><a class="" href="introduction.html"><span class="header-section-number">20</span> Introduction</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">21</span> Clustering</a></li>
<li><a class="" href="model-based-clustering.html"><span class="header-section-number">22</span> Model based clustering</a></li>
<li><a class="" href="hierarchical-clustering.html"><span class="header-section-number">23</span> Hierarchical clustering</a></li>
<li><a class="" href="references.html">References</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="alt-pca.html"><span class="header-section-number">A</span> PCA and alternating regression</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="qda" class="section level1">
<h1>
<span class="header-section-number">12</span> QDA<a class="anchor" aria-label="anchor" href="#qda"><i class="fas fa-link"></i></a>
</h1>
<p>Similarly to the way we derived the LDA classifier in class, if one relaxes the assumption
that the conditional distribution of the vector of features <strong>X</strong> in each class has
the same covariance matrix (<em>shape</em>) (but still assumes that these distributions are
Gaussian), then it is (again) easy to find a closed form for the conditional probability
of each class (conditional on a vector of features <strong>X</strong>). As in the LDA case,
these conditional class probabilities (aka <em>posterior probabilities</em>) depend on the
parameters of the assumed model for the conditional distributions of <strong>X</strong> in each
class. So, again, we estimate those parameters from the training set (usin the observations
in each group) and plug them in to compute the conditional class probabilities.</p>
<p>Similarly to what we did for LDA, it is easy to see that in this case the class
boundaries are quadratic functions of the vector of features <strong>X</strong>.</p>
<p>We illustrate QDA on the same <code>vaso</code> data we used before. We first load the
data, and train a QDA classifier using the function <code>qda</code> in package <code>MASS</code>
(this can also be written as <code><a href="https://rdrr.io/pkg/MASS/man/qda.html">MASS::qda()</a></code>).</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">vaso</span>, package <span class="op">=</span> <span class="st">"robustbase"</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>
<span class="va">a.qda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/qda.html">qda</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">vaso</span><span class="op">)</span></code></pre></div>
<p>We now build a relatively fine grid of points in the domain of our
2-dimensional vector of features and use the <code>predict</code> method
associated with a <code>qda</code> object to predict the conditional probability of
class <code>blue</code>:</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">xvol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span>, length <span class="op">=</span> <span class="fl">200</span><span class="op">)</span>
<span class="va">xrat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span>, length <span class="op">=</span> <span class="fl">200</span><span class="op">)</span>
<span class="va">xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">xvol</span>, <span class="va">xrat</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">xx</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Volume"</span>, <span class="st">"Rate"</span><span class="op">)</span>
<span class="va">pr.qda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">a.qda</span>, newdata <span class="op">=</span> <span class="va">xx</span><span class="op">)</span><span class="op">$</span><span class="va">posterior</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="va">xrat</span>, <span class="va">xvol</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">pr.qda</span>, <span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,
  ylab <span class="op">=</span> <span class="st">"Volume"</span>, xlab <span class="op">=</span> <span class="st">"Rate"</span>, cex.lab <span class="op">=</span> <span class="fl">1.5</span>, cex.axis <span class="op">=</span> <span class="fl">1.5</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">Volume</span> <span class="op">~</span> <span class="va">Rate</span>,
  data <span class="op">=</span> <span class="va">vaso</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"blue"</span><span class="op">)</span><span class="op">[</span><span class="va">Y</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">xrat</span>, <span class="va">xvol</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">pr.qda</span>, <span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span>,
  col <span class="op">=</span> <span class="st">"gray30"</span>, levels <span class="op">=</span> <span class="fl">.5</span>,
  drawlabels <span class="op">=</span> <span class="cn">FALSE</span>, lwd <span class="op">=</span> <span class="fl">3</span>, add <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/qda2-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We used the function <code>contour</code> above to draw the boundary between
classes (the set of points where the probability of blue is equal to
the probability of red).</p>
<div id="sensitivity-to-the-gaussian-assumption" class="section level2">
<h2>
<span class="header-section-number">12.1</span> Sensitivity to the Gaussian assumption<a class="anchor" aria-label="anchor" href="#sensitivity-to-the-gaussian-assumption"><i class="fas fa-link"></i></a>
</h2>
<p>We discussed in class (with the help of a simple example) the sensitivity of
QDA to the assumed specific conditional distribution of the
features within each class. It is very easy to see that LDA may also
be affected by similar problems. This is not at all surprising–in many
cases optimal methods obtained under certain conditions are very
sensitive to the vailidity of the assumptions used in their derivation.</p>
<p>It is interesting to note (as discussed in class) that logistic
regression was not affected by the “good outliers” we included in
the data. Considering where these “good outliers” are (in terms
of their corresponding likelihood values), this is probably
not surprising. Note, furthermore, that both QDA (and LDA) and logistic regression
are classifiers that require the estimation of parameters (maybe we
can call them <em>parametric classifiers</em>?), and in all cases considered so far
the parameters were estimated using maximum likelihood. However their
sensitivity to this kind of outliers is very different.</p>
</div>
<div id="more-than-2-classes-the-handwritten-digit-recognition-data" class="section level2">
<h2>
<span class="header-section-number">12.2</span> More than 2 classes – The handwritten digit recognition data<a class="anchor" aria-label="anchor" href="#more-than-2-classes-the-handwritten-digit-recognition-data"><i class="fas fa-link"></i></a>
</h2>
<p>As you may have noted, all the classification methods we have seen so far can
be used in applications with an arbitrary number of classes. We will now
illustrate them on the well-known Handwritten Digit Recognition Data
(as usual, see <code><a href="https://rdrr.io/pkg/ElemStatLearn/man/zip.train.html">help(zip.train, package='ElemStatLearn')</a></code>). We first
load the data, and extract the images corresponding to digits 0, 1 and
8. These should be challenging enough to discriminate given their
similar shapes.</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">zip.train</span>, package <span class="op">=</span> <span class="st">"ElemStatLearn"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">zip.test</span>, package <span class="op">=</span> <span class="st">"ElemStatLearn"</span><span class="op">)</span>
<span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="va">zip.train</span><span class="op">[</span><span class="va">zip.train</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">8</span><span class="op">)</span>, <span class="op">]</span>
<span class="va">x.te</span> <span class="op">&lt;-</span> <span class="va">zip.test</span><span class="op">[</span><span class="va">zip.test</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">8</span><span class="op">)</span>, <span class="op">]</span></code></pre></div>
<p>The values of the pixes of each image are in the rows of the
corresponding matrix (columns 2:256), and the true class of each image is in
the first column. Note that there are relatively few 8’s in this training set:</p>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;    0    1    8 </span>
<span class="co">#&gt; 1194 1005  542</span></code></pre></div>
<p>To display these 16x16 images we adapt a simple function to plot matrices:</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># ----- Define a function for plotting a matrix ----- #</span>
<span class="co"># modified from: http://www.phaget4.org/R/image_matrix.html</span>
<span class="va">myImagePlot</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">min</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="va">max</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="va">ColorRamp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/gray.html">grey</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, length <span class="op">=</span> <span class="fl">256</span><span class="op">)</span><span class="op">)</span>
  <span class="va">ColorLevels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">min</span>, <span class="va">max</span>, length <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">ColorRamp</span><span class="op">)</span><span class="op">)</span>
  <span class="co"># Reverse Y axis</span>
  <span class="va">reverse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">:</span><span class="fl">1</span>
  <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">reverse</span>, <span class="op">]</span>
  <span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,
    col <span class="op">=</span> <span class="va">ColorRamp</span>, xlab <span class="op">=</span> <span class="st">""</span>,
    ylab <span class="op">=</span> <span class="st">""</span>, axes <span class="op">=</span> <span class="cn">FALSE</span>, zlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">min</span>, <span class="va">max</span><span class="op">)</span>
  <span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Next we choose 9 images at random from the training set,
and display them in a 3x3 array of images:</p>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a</span> <span class="op">&lt;-</span> <span class="va">x.tr</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">987</span><span class="op">)</span>
<span class="va">sa</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">a</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">9</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu">myImagePlot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">a</span><span class="op">[</span><span class="va">sa</span><span class="op">[</span><span class="va">j</span><span class="op">]</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="fl">16</span>, <span class="fl">16</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/ziplot9-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We can also show the “average 8” in the training set:</p>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">myImagePlot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">x.tr</span>, subset <span class="op">=</span> <span class="op">(</span><span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span>, select <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span>, <span class="fl">16</span>, <span class="fl">16</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/zipav-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb145"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># alternatively: myImagePlot(t(matrix(colMeans(a[a[,1]==8,-1]), 16, 16)))</span></code></pre></div>
<p>We will now use LDA, QDA and a multinomial logistic model. The
latter is the natural extension of logistic regression to more than
2 classes. You can easily derive it yourself by assuming that the response
variable has a multinomial distribution and modeling each
conditional probability as a (different) logistic function of the
vector <strong>X</strong> of features. Note that if there are <em>K</em> classes you only need
to model <em>K-1</em> of these conditional class probabilities. The derivation
is left as an easy exercise for you.</p>
<p>Note that the data is stored in a matrix, but the use of
<code><a href="https://rdrr.io/pkg/MASS/man/lda.html">lda()</a></code>, <code><a href="https://rdrr.io/pkg/MASS/man/qda.html">qda()</a></code>, etc. is clearer when you have your data
in a <code>data frame</code> (as you can then refer to features by their
names and use the <code>data</code> argument). So, we first transform
our matrix into a data frame, and name the resulting variables
<em>V1</em>, <em>V2</em>, …, <em>V257</em>:</p>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x.tr</span><span class="op">)</span>
<span class="va">x.te</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x.te</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">x.te</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">x.tr</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">257</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span></code></pre></div>
<p>Now we use <code>lda</code> and <code>multinom</code> (this last one from package <code>nnet</code>) to train
an LDA and a multinomial classifier to these 3-class data:</p>
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/lda.html">lda</a></span><span class="op">(</span><span class="va">V1</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">V257</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span> <span class="co"># x.tr[,1] ~ x[, 2:256])</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">nnet</a></span><span class="op">)</span>
<span class="va">a.log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nnet/man/multinom.html">multinom</a></span><span class="op">(</span><span class="va">V1</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">V257</span>, data <span class="op">=</span> <span class="va">x.tr</span>, maxit <span class="op">=</span> <span class="fl">5000</span><span class="op">)</span>
<span class="co">#&gt; # weights:  771 (512 variable)</span>
<span class="co">#&gt; initial  value 3011.296283 </span>
<span class="co">#&gt; iter  10 value 27.327939</span>
<span class="co">#&gt; iter  20 value 8.491334</span>
<span class="co">#&gt; iter  30 value 2.640128</span>
<span class="co">#&gt; iter  40 value 1.228798</span>
<span class="co">#&gt; iter  50 value 0.663474</span>
<span class="co">#&gt; iter  60 value 0.391984</span>
<span class="co">#&gt; iter  70 value 0.212952</span>
<span class="co">#&gt; iter  80 value 0.114876</span>
<span class="co">#&gt; iter  90 value 0.053465</span>
<span class="co">#&gt; iter 100 value 0.026628</span>
<span class="co">#&gt; iter 110 value 0.014534</span>
<span class="co">#&gt; iter 120 value 0.009281</span>
<span class="co">#&gt; iter 130 value 0.006623</span>
<span class="co">#&gt; iter 140 value 0.004210</span>
<span class="co">#&gt; iter 150 value 0.002723</span>
<span class="co">#&gt; iter 160 value 0.001851</span>
<span class="co">#&gt; iter 170 value 0.001318</span>
<span class="co">#&gt; iter 180 value 0.001036</span>
<span class="co">#&gt; iter 190 value 0.000580</span>
<span class="co">#&gt; iter 200 value 0.000516</span>
<span class="co">#&gt; iter 210 value 0.000304</span>
<span class="co">#&gt; iter 220 value 0.000249</span>
<span class="co">#&gt; iter 230 value 0.000218</span>
<span class="co">#&gt; final  value 0.000090 </span>
<span class="co">#&gt; converged</span></code></pre></div>
<p>(Question: <em>Why do I remove variable <code>V257</code> from the models above?</em>)</p>
<p>As a side commment: note how slow is the convergence of <code>multinom</code>. This is not unusual,
and it has to do with how neural networks are trained. Refer to
the corresponding help page for more information. We will probably
discuss this further later in the course.</p>
<p>For now we obtain the predictions on the test set and build a
matrix of classification errors for each classifier. For LDA we have:</p>
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pr.lda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">a</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span><span class="op">$</span><span class="va">class</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">pr.lda</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;       </span>
<span class="co">#&gt; pr.lda   0   1   8</span>
<span class="co">#&gt;      0 353   2   9</span>
<span class="co">#&gt;      1   0 258   0</span>
<span class="co">#&gt;      8   6   4 157</span></code></pre></div>
<p>For the logistic multinomial classifier we have:</p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pr.log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">a.log</span>, newdata <span class="op">=</span> <span class="va">x.te</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">pr.log</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;       </span>
<span class="co">#&gt; pr.log   0   1   8</span>
<span class="co">#&gt;      0 342   3  13</span>
<span class="co">#&gt;      1  12 258  10</span>
<span class="co">#&gt;      8   5   3 143</span></code></pre></div>
<p>We now attempt to train a QDA classifier:</p>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a.qda</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/try.html">try</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/qda.html">qda</a></span><span class="op">(</span><span class="va">V1</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">V257</span>, data <span class="op">=</span> <span class="va">x.tr</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Error in qda.default(x, grouping, ...) : rank deficiency in group 0</span>
<span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">a.qda</span><span class="op">)</span>
<span class="co">#&gt; [1] "try-error"</span></code></pre></div>
<p>This classifier cannot be trained on these data. The problem is that
the training set for at least one class is rank deficient (which can
be found by looking at the error message stored in the returned
object <code>a.qda</code></p>
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a.qda</span>
<span class="co">#&gt; [1] "Error in qda.default(x, grouping, ...) : rank deficiency in group 0\n"</span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "try-error"</span>
<span class="co">#&gt; attr(,"condition")</span>
<span class="co">#&gt; &lt;simpleError in qda.default(x, grouping, ...): rank deficiency in group 0&gt;</span></code></pre></div>
<p>Indeed, we have:</p>
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x1</span> <span class="op">&lt;-</span> <span class="va">x.tr</span><span class="op">[</span><span class="va">x.tr</span><span class="op">$</span><span class="va">V1</span> <span class="op">==</span> <span class="fl">0</span>, <span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span>
<span class="co">#&gt; [1] 1194  257</span>
<span class="fu"><a href="https://rdrr.io/r/base/qr.html">qr</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">$</span><span class="va">rank</span>
<span class="co">#&gt; [1] 254</span></code></pre></div>
<p>The questions for you are:</p>
<ul>
<li>why is this rank deficiency a problem for QDA, but not for LDA, or a multinomial model?</li>
<li>can we do anything to train a (possibly different) QDA classifier to these data?</li>
</ul>
<!-- #### (Optional section) Sensitivity & Specificity --><!-- **This section is still under revision, read at your own risk.** --><!-- Any binary decision-making process has two important features, generally called --><!-- senstivity and specificity. Intuitively these measure: --><!-- * how often it makes correct decisions (how many *cats* are correctly classified as *cats*?) (sensitivity); and --><!-- * how often it makes correct positive calls (how many objects classified as *cats* are indeed *cats*?) (equivalentely, how many *not cats* are **not called cats**?) (specificity).  --><!-- We refer back to the `vaso` data. We train both an LDA and a QDA classifier. We can  --><!-- derive the associated sensitivity and specificity from the misclassification table. Note --><!-- that since there is no independent test set these figures may be misleading.  --><!-- ```{r sens1, fig.width=6, fig.height=6, message=FALSE, warning=FALSE} --><!-- a <- lda(Y ~ . , data=vaso) --><!-- a.qda <- qda(Y ~ . , data=vaso) --><!-- pr.lda <- as.numeric(predict(a)$class) --><!-- pr.qda <- as.numeric(predict(a.qda)$class) --><!-- table(pr.lda, vaso$Y) --><!-- table(pr.qda, vaso$Y) --><!-- ``` --><!-- Hence we can estimate the sensitivities of LDA and QDA as 17/19 and 16/19  --><!-- respectively. Their specificities are both 16/20.  --><!-- # sensitivity  --><!-- # LDA: 16/20 = 4/5 --><!-- # QDA: 16/20  --><!-- # specificity --><!-- # LDA: 17/19 --><!-- # QDA: 16/19 --><!-- For the zip code data: --><!-- ```{r zip3, fig.width=6, fig.height=6, message=FALSE, warning=FALSE} --><!-- data(zip.train, package='ElemStatLearn')  --><!-- data(zip.test, package='ElemStatLearn') --><!-- x.tr <- data.frame( zip.train[ zip.train[, 1] %in% c(3, 8), ] ) --><!-- x.te <- data.frame( zip.test[ zip.test[, 1] %in% c(3, 8), ] ) --><!-- names( x.te ) <- names( x.tr  ) <- paste('V', 1:257, sep='') --><!-- a <- lda(V1 ~ . - V257, data=x.tr) --><!-- te.lda <- as.numeric(predict(a, newdata=x.te)$class) --><!-- table(te.lda, x.te$V1) --><!-- ``` --><!-- # sensitivity - test --><!-- # 350/ 359 = 97.4% --><!-- # specificity - test --><!-- # 160 / 166 = 96.4% --><!-- # build the ROC curve --><!-- te.lda <- predict(a, newdata=x.te)$posterior[,1] --><!-- sens <- spec <- rep(0, 50) --><!-- als <- seq(0, 1, length=51) --><!-- for(i in 1:50) { --><!--   npr.1 <- (te.lda > als[i]) --><!--   npr.2 <- !npr.1 --><!--   sens[i] <- sum( (as.numeric(as.factor(x.te$V1)) == 1) & npr.1 ) --><!--   spec[i] <- sum( (as.numeric(as.factor(x.te$V1)) == 2) & npr.2 ) --><!-- } --><!-- sens <- sens / sum(as.numeric(as.factor(x.te$V1)) == 1) --><!-- spec <- spec / sum(as.numeric(as.factor(x.te$V1)) == 2) --><!-- plot(1-spec, sens, type='b', ylim=c(0,1), xlim=c(0,1)) -->
</div>
<div id="k-nearest-neighbours-k-nn" class="section level2">
<h2>
<span class="header-section-number">12.3</span> K-Nearest Neighbours (K-NN)<a class="anchor" aria-label="anchor" href="#k-nearest-neighbours-k-nn"><i class="fas fa-link"></i></a>
</h2>
<p>Perhaps the intuitively simplest model-free estimator for conditional class probabilities
for a given set of feature values <strong>X</strong> is the one based on nearest neighbours
(as discussed in class). It is similar (in <em>spirit</em>) to the kernel regression
estimator in the continuous-response regression setting. More specifically,
it can be thought of as a variable-bandwidth kernel estimator. For a
point <strong>X</strong> in the feature space we look at the proportion of observations
in each class among <strong>X</strong>’s K-th closest neighbours. That is, of course, equivalent
to looking at all points <span class="math inline">\((Y_i, \mathbf{X}_i)\)</span> in the training set such that
<span class="math inline">\(\left\| \mathbf{X}_i - \mathbf{X} \right\| \le h_k\)</span>, where <span class="math inline">\(h_k\)</span> is the
distance from <strong>X</strong> to the K-th closest neighbour in the training set.
Refer to the discussion in class for more details.</p>
<p>Here we will illustrate K-NN classifiers on the toy <code>vaso</code> example (to be able to
visualize the results more easily), and also on the hand written digits data.
We will use the function <code>knn</code> in package <code>class</code>. This function takes a
training set, and also a <em>test</em> set (i.e. a different data set containing the
observations to be predicted). In the example below we first create (as
we have done before) a 200 x 200 grid of points and display the resulting
predicted probabilities (or the corresponding class with highest conditional
probability).</p>
<p>We first we use a trivial 1-NN classifier: the estimated conditional probabilities
for each class at a point <strong>X</strong>, will simply be 0 or 1 depending on the class of the closest
neighbour to <strong>X</strong> in the training set.</p>
<div class="sourceCode" id="cb153"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">class</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">vaso</span>, package <span class="op">=</span> <span class="st">"robustbase"</span><span class="op">)</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span>, length <span class="op">=</span> <span class="fl">200</span><span class="op">)</span>
<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span>, length <span class="op">=</span> <span class="fl">200</span><span class="op">)</span>
<span class="va">xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span><span class="op">)</span>
<span class="va">u1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">vaso</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">vaso</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">xx</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">u1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">u1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">u1</span>, <span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,
  ylab <span class="op">=</span> <span class="st">"Volume"</span>, xlab <span class="op">=</span> <span class="st">"Rate"</span>, main <span class="op">=</span> <span class="st">"1-NN"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">Volume</span> <span class="op">~</span> <span class="va">Rate</span>,
  data <span class="op">=</span> <span class="va">vaso</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"blue"</span><span class="op">)</span><span class="op">[</span><span class="va">Y</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/knn1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We repeat the analysis with a 5-NN classifier. Now the estimated
conditional probabilities
for each <strong>X</strong> in the grid can be 0, 0.20, 0.40, 0.60, 0.80 or 1 (why?)
The function <code>knn</code> returns the estimated probabilities in the
<code>'prob'</code> attribute of the returned object, so we need to use the
function <code>attr</code> to extract it (as usual, the R help pages are
a good source of information if you have any questions about the
code below):</p>
<div class="sourceCode" id="cb154"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">u5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">vaso</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">vaso</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">xx</span>, k <span class="op">=</span> <span class="fl">5</span>, prob <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
  <span class="st">"prob"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">u5</span>, <span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,
  ylab <span class="op">=</span> <span class="st">"Volume"</span>, xlab <span class="op">=</span> <span class="st">"Rate"</span>, main <span class="op">=</span> <span class="st">"5-NN"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">Volume</span> <span class="op">~</span> <span class="va">Rate</span>,
  data <span class="op">=</span> <span class="va">vaso</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,
  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"blue"</span><span class="op">)</span><span class="op">[</span><span class="va">Y</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/knn5-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We now turn to the digits data. We now look at the images
for digits 1, 3 and 8 and create the corresponding
training and test sets:</p>
<div class="sourceCode" id="cb155"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">zip.train</span>, package <span class="op">=</span> <span class="st">"ElemStatLearn"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">zip.test</span>, package <span class="op">=</span> <span class="st">"ElemStatLearn"</span><span class="op">)</span>
<span class="va">x.tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">zip.train</span><span class="op">[</span><span class="va">zip.train</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">8</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span>
<span class="va">x.te</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">zip.test</span><span class="op">[</span><span class="va">zip.test</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">8</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">x.te</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">x.tr</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">257</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span></code></pre></div>
<p>We now train 1-, 5-, 10- and 50-NN classifiers and evaluate them on
the test set. We report the misclassification rate on the test set,
along with the corresponding tables:</p>
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">u1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">x.te</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">u1</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt; u1    1   3   8</span>
<span class="co">#&gt;   1 261   0   0</span>
<span class="co">#&gt;   3   3 162   9</span>
<span class="co">#&gt;   8   0   4 157</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">u1</span> <span class="op">!=</span> <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.02684564</span>

<span class="va">u5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">x.te</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">u5</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt; u5    1   3   8</span>
<span class="co">#&gt;   1 261   1   0</span>
<span class="co">#&gt;   3   3 161   7</span>
<span class="co">#&gt;   8   0   4 159</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">u5</span> <span class="op">!=</span> <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.02516779</span>

<span class="va">u10</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">x.te</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">u10</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt; u10   1   3   8</span>
<span class="co">#&gt;   1 261   1   3</span>
<span class="co">#&gt;   3   3 163  12</span>
<span class="co">#&gt;   8   0   2 151</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">u10</span> <span class="op">!=</span> <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.0352349</span>

<span class="va">u50</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span>train <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, cl <span class="op">=</span> <span class="va">x.tr</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, test <span class="op">=</span> <span class="va">x.te</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">u50</span>, <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt;    </span>
<span class="co">#&gt; u50   1   3   8</span>
<span class="co">#&gt;   1 261   2   7</span>
<span class="co">#&gt;   3   3 159  18</span>
<span class="co">#&gt;   8   0   5 141</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">u50</span> <span class="op">!=</span> <span class="va">x.te</span><span class="op">$</span><span class="va">V1</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.05872483</span></code></pre></div>
<p>Note how the performance of the K-NN classifier in this case
stops improving when K is larger than 5. Since the number <em>K</em> of
nearest neighbours is in fact a tuning constant that needs to
be chosen by the user, how would do it in an objective way?
What would you do if you didn’t have a test set available?</p>
</div>
<div id="challenges-for-k-nn-classifiers" class="section level2">
<h2>
<span class="header-section-number">12.4</span> Challenges for K-NN classifiers<a class="anchor" aria-label="anchor" href="#challenges-for-k-nn-classifiers"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>It is easy to see that they suffer from the <em>curse of dimensionality</em>.</li>
<li>Factor or binary features need to be treated with care.</li>
<li>Euclidean distances do not reflect <em>shape</em> of features in each class (i.e. the
conditional distribution of <strong>X</strong> in each class). Class-wise pre-standardization
(whitening) might be useful.</li>
</ul>
<p>To illustrate the last point, consider this toy synthetic example we discussed in class:</p>
<div class="inline-figure"><img src="31-qda-knn_files/figure-html/knntrouble-1.png" width="90%" style="display: block; margin: auto;"></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="parametric-classifiers.html"><span class="header-section-number">11</span> Parametric classifiers</a></div>
<div class="next"><a href="classification-trees.html"><span class="header-section-number">13</span> Classification Trees</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#qda"><span class="header-section-number">12</span> QDA</a></li>
<li><a class="nav-link" href="#sensitivity-to-the-gaussian-assumption"><span class="header-section-number">12.1</span> Sensitivity to the Gaussian assumption</a></li>
<li><a class="nav-link" href="#more-than-2-classes-the-handwritten-digit-recognition-data"><span class="header-section-number">12.2</span> More than 2 classes – The handwritten digit recognition data</a></li>
<li><a class="nav-link" href="#k-nearest-neighbours-k-nn"><span class="header-section-number">12.3</span> K-Nearest Neighbours (K-NN)</a></li>
<li><a class="nav-link" href="#challenges-for-k-nn-classifiers"><span class="header-section-number">12.4</span> Challenges for K-NN classifiers</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>UBC Stat 406 Worksheets</strong>" was written by Daniel J. McDonald and Matías Salibán-Barrera. It was last built on 2021-08-17.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
